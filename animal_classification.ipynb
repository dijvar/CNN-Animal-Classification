{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mMTK-BlsAP1"
      },
      "source": [
        "**Drive'Ä± baÄŸlÄ±yoruz.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1VlW3SYVDfr",
        "outputId": "ada6c64a-e1e3-4f66-da85-aba5f31d6659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: add drive mount code\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPobdwjdsH6J"
      },
      "source": [
        "**Ekran kartÄ±nÄ±, ekran kartÄ± hafÄ±zasÄ±nÄ±, Cuda versiyonunu, driver versiyonunu kontrol ediyoruz.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUmTEIzYkVib",
        "outputId": "2ceb70cc-2d5a-4377-b2ed-943db6a626fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 22 20:21:23 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0              46W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY5tPr6Z63A1"
      },
      "source": [
        "**Veri setini Kaggle'dan yÃ¼klÃ¼yoruz.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR9BJ1B96trS",
        "outputId": "930cbbf3-5dc5-4b30-9b51-952787959a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rrebirrth/animals-with-attributes-2?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.0G/13.0G [01:02<00:00, 224MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "rrebirrth_animals_with_attributes_2_path = kagglehub.dataset_download('rrebirrth/animals-with-attributes-2')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwcn_9a85kzs"
      },
      "source": [
        "# Drive da Ã§alÄ±ÅŸmak iÃ§in kullanÄ±lacak\n",
        "\n",
        "**!!**: *Kendi drive dizininizi yazÄ±n.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S42gnzhdXnxR",
        "outputId": "3837cd39-3c78-451b-a997-bcacf4038f1d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dizin kontrolÃ¼\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITPwwhLojrjY",
        "outputId": "61c21766-d274-4339-c9de-dcc09928faaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mconfig\u001b[0m/  README.md  requirements.txt  \u001b[01;34msrc\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# Drive dizininin iÃ§eriÄŸi\n",
        "%ls /content/drive/MyDrive/bootcamp/animal_classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB-19XIn_apj",
        "outputId": "a7e50bb7-49b7-4b23-fcd9-7623cb2efd68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/bootcamp/animal_classification\n"
          ]
        }
      ],
      "source": [
        "#dizini deÄŸiÅŸtiriyoruz, drive da Ã§alÄ±ÅŸalÄ±m: /content/drive/MyDrive/bootcamp/animal_classification/\n",
        "%cd /content/drive/MyDrive/bootcamp/animal_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jioLwmeH7q5Q"
      },
      "source": [
        "**Veri setinden sadece kullanÄ±lacak sÄ±nÄ±flarÄ±n ilk 650 gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ dizine kaydediyoruz.**\n",
        "\n",
        "---\n",
        "\n",
        "***SÄ±nÄ±flar:***\n",
        "\n",
        "- *collie*\n",
        "- *dolphin*\n",
        "- *elephant*\n",
        "- *fox*\n",
        "- *moose*\n",
        "- *rabbit*\n",
        "- *sheep*\n",
        "- *squirrel*\n",
        "- *giant+panda*\n",
        "- *polar+bear*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCRoRwGS6_ok",
        "outputId": "51e05435-e181-470d-855e-b32aae15d3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images copied successfully!\n",
            "giant+panda: 650 images, 0 empty\n",
            "polar+bear: 650 images, 0 empty\n",
            "rabbit: 650 images, 0 empty\n",
            "elephant: 650 images, 0 empty\n",
            "collie: 650 images, 0 empty\n",
            "squirrel: 650 images, 0 empty\n",
            "sheep: 650 images, 0 empty\n",
            "fox: 650 images, 0 empty\n",
            "moose: 650 images, 0 empty\n",
            "dolphin: 650 images, 0 empty\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize the dictionary to hold paths for each animal\n",
        "image_paths = {}\n",
        "\n",
        "# Base directory for your dataset\n",
        "base_path = \"/root/.cache/kagglehub/datasets/rrebirrth/animals-with-attributes-2/versions/1/Animals_with_Attributes2/JPEGImages/\"\n",
        "\n",
        "# List of animals to search for\n",
        "animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
        "\n",
        "# Traverse the directory structure to collect image paths\n",
        "for dirname, _, filenames in os.walk(base_path):\n",
        "    for animal in animals:\n",
        "        if animal in dirname:\n",
        "            if animal not in image_paths:\n",
        "                image_paths[animal] = []\n",
        "            for filename in filenames:\n",
        "                image_paths[animal].append(os.path.join(dirname, filename))\n",
        "\n",
        "datasets_dir = \"dataset/raw\"\n",
        "# Create the 'dataset/raw' directory if it doesn't exist\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "\n",
        "# Copy the first 650 images for each animal\n",
        "for animal, paths in image_paths.items():\n",
        "    # Create a directory for the current animal within 'dataset/raw'\n",
        "    animal_dir = os.path.join(datasets_dir, animal)\n",
        "    os.makedirs(animal_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the first 650 images\n",
        "    for i, path in enumerate(paths[:650]):\n",
        "        destination_path = os.path.join(animal_dir, os.path.basename(path))\n",
        "        shutil.copy(path, destination_path)\n",
        "\n",
        "print(\"Images copied successfully!\")\n",
        "\n",
        "# Get a list of all class names (subdirectories) within the base directory\n",
        "class_names = [f for f in os.listdir(datasets_dir) if os.path.isdir(os.path.join(datasets_dir, f))]\n",
        "\n",
        "# Loop through each class name and count the images\n",
        "for class_name in class_names:\n",
        "    # Construct the path to the current class's directory\n",
        "    class_dir = os.path.join(datasets_dir, class_name)\n",
        "\n",
        "    # Initialize counters for total and empty images\n",
        "    total_images = 0\n",
        "    empty_images = 0\n",
        "\n",
        "    # Loop through files in the class directory\n",
        "    for filename in os.listdir(class_dir):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "\n",
        "        # Check if it's a file (not a subdirectory)\n",
        "        if os.path.isfile(file_path):\n",
        "            total_images += 1\n",
        "\n",
        "            # Attempt to open the image using Pillow\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    # Check if the image is empty (size is 0)\n",
        "                    if img.size == (0, 0):\n",
        "                        empty_images += 1\n",
        "            except IOError:\n",
        "                # Handle cases where the file is not a valid image\n",
        "                print(f\"Warning: Could not open or read image file: {file_path}\")\n",
        "\n",
        "    # Print the class name, total images, and empty image count\n",
        "    print(f\"{class_name}: {total_images} images, {empty_images} empty\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR4_jixi6MZ1"
      },
      "source": [
        "# Colab `/content` dizininde Ã§alÄ±ÅŸmak iÃ§in kullanÄ±lacak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rn_HzLa4YiLb",
        "outputId": "a1924bbc-a192-42d6-b720-e02b8aa20a8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cp4gzwc6aI0",
        "outputId": "455c2204-77c4-42f9-cca4-ce95f28d1a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CNN-Animal-Classification'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 34 (delta 12), reused 18 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 71.37 KiB | 4.20 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dijvar/CNN-Animal-Classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RE55dex7JlG",
        "outputId": "1bb96785-d95a-477b-ed4e-574da9541fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CNN-Animal-Classification\n"
          ]
        }
      ],
      "source": [
        "%cd CNN-Animal-Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Veri setinden sadece kullanÄ±lacak sÄ±nÄ±flarÄ±n ilk 650 gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ dizine kaydediyoruz.**\n",
        "\n",
        "---\n",
        "\n",
        "***SÄ±nÄ±flar:***\n",
        "\n",
        "- *collie*\n",
        "- *dolphin*\n",
        "- *elephant*\n",
        "- *fox*\n",
        "- *moose*\n",
        "- *rabbit*\n",
        "- *sheep*\n",
        "- *squirrel*\n",
        "- *giant+panda*\n",
        "- *polar+bear*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzkxjPiU8EBj",
        "outputId": "51e05435-e181-470d-855e-b32aae15d3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images copied successfully!\n",
            "giant+panda: 650 images, 0 empty\n",
            "polar+bear: 650 images, 0 empty\n",
            "rabbit: 650 images, 0 empty\n",
            "elephant: 650 images, 0 empty\n",
            "collie: 650 images, 0 empty\n",
            "squirrel: 650 images, 0 empty\n",
            "sheep: 650 images, 0 empty\n",
            "fox: 650 images, 0 empty\n",
            "moose: 650 images, 0 empty\n",
            "dolphin: 650 images, 0 empty\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Initialize the dictionary to hold paths for each animal\n",
        "image_paths = {}\n",
        "\n",
        "# Base directory for your dataset\n",
        "base_path = \"/root/.cache/kagglehub/datasets/rrebirrth/animals-with-attributes-2/versions/1/Animals_with_Attributes2/JPEGImages/\"\n",
        "\n",
        "# List of animals to search for\n",
        "animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
        "\n",
        "# Traverse the directory structure to collect image paths\n",
        "for dirname, _, filenames in os.walk(base_path):\n",
        "    for animal in animals:\n",
        "        if animal in dirname:\n",
        "            if animal not in image_paths:\n",
        "                image_paths[animal] = []\n",
        "            for filename in filenames:\n",
        "                image_paths[animal].append(os.path.join(dirname, filename))\n",
        "\n",
        "datasets_dir = \"dataset/raw\"\n",
        "# Create the 'dataset/raw' directory if it doesn't exist\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "\n",
        "# Copy the first 650 images for each animal\n",
        "for animal, paths in image_paths.items():\n",
        "    # Create a directory for the current animal within 'dataset/raw'\n",
        "    animal_dir = os.path.join(datasets_dir, animal)\n",
        "    os.makedirs(animal_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the first 650 images\n",
        "    for i, path in enumerate(paths[:650]):\n",
        "        destination_path = os.path.join(animal_dir, os.path.basename(path))\n",
        "        shutil.copy(path, destination_path)\n",
        "\n",
        "print(\"Images copied successfully!\")\n",
        "\n",
        "# Get a list of all class names (subdirectories) within the base directory\n",
        "class_names = [f for f in os.listdir(datasets_dir) if os.path.isdir(os.path.join(datasets_dir, f))]\n",
        "\n",
        "# Loop through each class name and count the images\n",
        "for class_name in class_names:\n",
        "    # Construct the path to the current class's directory\n",
        "    class_dir = os.path.join(datasets_dir, class_name)\n",
        "\n",
        "    # Initialize counters for total and empty images\n",
        "    total_images = 0\n",
        "    empty_images = 0\n",
        "\n",
        "    # Loop through files in the class directory\n",
        "    for filename in os.listdir(class_dir):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "\n",
        "        # Check if it's a file (not a subdirectory)\n",
        "        if os.path.isfile(file_path):\n",
        "            total_images += 1\n",
        "\n",
        "            # Attempt to open the image using Pillow\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    # Check if the image is empty (size is 0)\n",
        "                    if img.size == (0, 0):\n",
        "                        empty_images += 1\n",
        "            except IOError:\n",
        "                # Handle cases where the file is not a valid image\n",
        "                print(f\"Warning: Could not open or read image file: {file_path}\")\n",
        "\n",
        "    # Print the class name, total images, and empty image count\n",
        "    print(f\"{class_name}: {total_images} images, {empty_images} empty\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtV7BgsWs9ZY"
      },
      "source": [
        "# Genel akÄ±ÅŸ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmy_qoCh2C_E",
        "outputId": "aade575f-5fc4-484c-af03-dadca5eb1b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.17.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tf_keras\n",
            "\u001b[33mWARNING: Package(s) not found: tensorflow-gpu\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Tensorflow sÃ¼rÃ¼mÃ¼nÃ¼ kontrol ediyoruz.\n",
        "!pip show tensorflow\n",
        "!pip show tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1n2xh_F3FRE",
        "outputId": "98326ad2-caf7-4d69-d6d0-c7c50f5e3906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow'un GPU kullanÄ±mÄ±nÄ± kontrol ediyoruz.\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9knrBKvv5B7"
      },
      "source": [
        "## Model EÄŸitimi ve DeÄŸerlendirmesi\n",
        "\n",
        "Bu komut, CNN modelinin eÄŸitimini ve deÄŸerlendirmesini baÅŸlatÄ±r. EÄŸitim sÃ¼reci aÅŸaÄŸÄ±daki adÄ±mlarÄ± iÃ§erir:\n",
        "\n",
        "1. **Veri Seti HazÄ±rlama**\n",
        "   - 10 sÄ±nÄ±f iÃ§in toplam 6500 gÃ¶rÃ¼ntÃ¼ (her sÄ±nÄ±f iÃ§in 650)\n",
        "   - Train (%70), Validation (%20), Test (%10) olarak bÃ¶lÃ¼nme\n",
        "   - GÃ¶rÃ¼ntÃ¼ boyutlarÄ± 224x224 ve 128x128 olarak yeniden boyutlandÄ±rma\n",
        "   - Piksel deÄŸerleri [0,1] aralÄ±ÄŸÄ±na normalizasyon\n",
        "\n",
        "2. **Grid Search Parametreleri**\n",
        "   - Input Size: [224, 128]\n",
        "   - Aktivasyon FonksiyonlarÄ±: [ReLU, PReLU, ELU]\n",
        "   - Learning Rate: [0.01, 0.001, 0.0001]\n",
        "   - Data Augmentation: [True, False]\n",
        "   - Toplam 36 farklÄ± model konfigÃ¼rasyonu test edilecek\n",
        "\n",
        "3. **Model Mimarisi**\n",
        "   - 3 KonvolÃ¼syon BloÄŸu (32-64-128 filtre)\n",
        "   - Batch Normalization\n",
        "   - MaxPooling\n",
        "   - Dropout (0.2)\n",
        "   - Dense Layer (256 nÃ¶ron)\n",
        "   - L2 Regularization (weight_decay=0.0001)\n",
        "\n",
        "4. **EÄŸitim DetaylarÄ±**\n",
        "   - Batch Size: 64\n",
        "   - Epochs: 100\n",
        "   - Early Stopping (patience=10)\n",
        "   - Model Checkpoint (en iyi validation accuracy)\n",
        "   - Wandb ile deney takibi\n",
        "\n",
        "5. **Test SenaryolarÄ±**\n",
        "   - Orijinal test gÃ¶rÃ¼ntÃ¼leri\n",
        "   - FarklÄ± Ä±ÅŸÄ±k koÅŸullarÄ±nda manipÃ¼le edilmiÅŸ gÃ¶rÃ¼ntÃ¼ler\n",
        "   - Renk sabitliÄŸi algoritmasÄ± uygulanmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ler\n",
        "\n",
        "6. **Ã‡Ä±ktÄ±lar**\n",
        "   - Her deney iÃ§in model performans metrikleri\n",
        "   - HÃ¼cre Ã§Ä±ktÄ±sÄ±nÄ±n sonunda en baÅŸarÄ±lÄ± deney yazdÄ±rÄ±lmÄ±ÅŸtÄ±r\n",
        "   - Test sonuÃ§larÄ± (accuracy ve loss deÄŸerleri)\n",
        "   - En baÅŸarÄ±lÄ± model konfigÃ¼rasyonu\n",
        "   - [Wandb](https://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/table?nw=nwuserorhandijvar) Ã¼zerinden detaylÄ± analiz grafikleri\n",
        "\n",
        "**!!:** EÄŸitim sÃ¼reci yaklaÅŸÄ±k 8-10 saat sÃ¼rebilir (GPU kullanÄ±mÄ±na baÄŸlÄ± olarak).\n",
        "\n",
        "*NVIDIA A100-40GB GPU ile yaklaÅŸÄ±k 4 saat sÃ¼rmÃ¼ÅŸtÃ¼r.*  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70EFBvYvBUVA",
        "outputId": "bcfe0c4d-a767-4709-afc4-7a9d2d53442d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_222725-gb9b1k0u/logs\u001b[0m\n",
            "\n",
            "Deney 12/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 13/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.01_aug_True\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_222916-xxqy6iw6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.01_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/xxqy6iw6\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 748ms/step - accuracy: 0.1014 - loss: 4.6496 - val_accuracy: 0.0989 - val_loss: 221.6738\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 670ms/step - accuracy: 0.0998 - loss: 5.0688 - val_accuracy: 0.0989 - val_loss: 122.7652\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.0985 - loss: 4.4100 - val_accuracy: 0.0989 - val_loss: 174.5680\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 694ms/step - accuracy: 0.1065 - loss: 4.0877 - val_accuracy: 0.1000 - val_loss: 475.7807\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 695ms/step - accuracy: 0.0995 - loss: 4.6632 - val_accuracy: 0.1011 - val_loss: 538.0807\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 670ms/step - accuracy: 0.0996 - loss: 4.5049 - val_accuracy: 0.0956 - val_loss: 578.4390\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 661ms/step - accuracy: 0.1006 - loss: 4.4458 - val_accuracy: 0.1011 - val_loss: 1642.4385\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1008 - loss: 4.7226 - val_accuracy: 0.1000 - val_loss: 1362.1412\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.0981 - loss: 4.1876 - val_accuracy: 0.1000 - val_loss: 1041.4438\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.0999 - loss: 4.2677 - val_accuracy: 0.1000 - val_loss: 2906.0334\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 689ms/step - accuracy: 0.1011 - loss: 3.8516 - val_accuracy: 0.1055 - val_loss: 870.2784\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 691ms/step - accuracy: 0.1019 - loss: 3.6443 - val_accuracy: 0.1132 - val_loss: 849.4594\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 692ms/step - accuracy: 0.1049 - loss: 3.4527 - val_accuracy: 0.1440 - val_loss: 1609.4484\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 673ms/step - accuracy: 0.1062 - loss: 3.4945 - val_accuracy: 0.1022 - val_loss: 488.4514\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.0943 - loss: 3.5127 - val_accuracy: 0.1011 - val_loss: 596.2832\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.0955 - loss: 3.6291 - val_accuracy: 0.1000 - val_loss: 1163.8928\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 661ms/step - accuracy: 0.1212 - loss: 3.3076 - val_accuracy: 0.1011 - val_loss: 640.6288\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1012 - loss: 3.0980 - val_accuracy: 0.1341 - val_loss: 719.6188\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 670ms/step - accuracy: 0.1098 - loss: 2.9090 - val_accuracy: 0.1000 - val_loss: 1363.4552\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.1071 - loss: 3.0249 - val_accuracy: 0.1055 - val_loss: 1013.9277\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.1046 - loss: 3.2484 - val_accuracy: 0.1198 - val_loss: 952.7524\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 661ms/step - accuracy: 0.1068 - loss: 3.0252 - val_accuracy: 0.1231 - val_loss: 580.8109\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.1114 - loss: 2.9740 - val_accuracy: 0.1011 - val_loss: 1350.2167\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=5.2224, acc=0.1005, val_loss=221.6738, val_acc=0.0989\n",
            "Epoch 2: loss=4.8281, acc=0.1063, val_loss=122.7652, val_acc=0.0989\n",
            "Epoch 3: loss=4.3540, acc=0.1019, val_loss=174.5680, val_acc=0.0989\n",
            "Epoch 4: loss=4.1814, acc=0.0995, val_loss=475.7807, val_acc=0.1000\n",
            "Epoch 5: loss=4.6336, acc=0.0981, val_loss=538.0807, val_acc=0.1011\n",
            "Epoch 6: loss=4.3967, acc=0.1011, val_loss=578.4390, val_acc=0.0956\n",
            "Epoch 7: loss=4.5321, acc=0.0926, val_loss=1642.4385, val_acc=0.1011\n",
            "Epoch 8: loss=4.5938, acc=0.1052, val_loss=1362.1412, val_acc=0.1000\n",
            "Epoch 9: loss=4.1779, acc=0.1014, val_loss=1041.4438, val_acc=0.1000\n",
            "Epoch 10: loss=4.1319, acc=0.0951, val_loss=2906.0334, val_acc=0.1000\n",
            "Epoch 11: loss=3.7424, acc=0.0940, val_loss=870.2784, val_acc=0.1055\n",
            "Epoch 12: loss=3.5945, acc=0.1011, val_loss=849.4594, val_acc=0.1132\n",
            "Epoch 13: loss=3.4040, acc=0.0995, val_loss=1609.4484, val_acc=0.1440\n",
            "Epoch 14: loss=3.5530, acc=0.0986, val_loss=488.4514, val_acc=0.1022\n",
            "Epoch 15: loss=3.5708, acc=0.0956, val_loss=596.2832, val_acc=0.1011\n",
            "Epoch 16: loss=3.5427, acc=0.1027, val_loss=1163.8928, val_acc=0.1000\n",
            "Epoch 17: loss=3.2072, acc=0.1052, val_loss=640.6288, val_acc=0.1011\n",
            "Epoch 18: loss=3.0744, acc=0.1011, val_loss=719.6188, val_acc=0.1341\n",
            "Epoch 19: loss=2.9454, acc=0.1022, val_loss=1363.4552, val_acc=0.1000\n",
            "Epoch 20: loss=3.0642, acc=0.1085, val_loss=1013.9277, val_acc=0.1055\n",
            "Epoch 21: loss=3.2066, acc=0.1041, val_loss=952.7524, val_acc=0.1198\n",
            "Epoch 22: loss=3.0640, acc=0.1069, val_loss=580.8109, val_acc=0.1231\n",
            "Epoch 23: loss=2.9452, acc=0.1022, val_loss=1350.2167, val_acc=0.1011\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.01_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1624.2069\n",
            "Accuracy: 0.1354\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 1066.2054\n",
            "Accuracy: 0.1361\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1609.2324\n",
            "Accuracy: 0.1368\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–…â–‡â–…â–„â–ƒâ–…â–â–‡â–…â–‚â–‚â–…â–„â–„â–‚â–…â–‡â–…â–…â–ˆâ–†â–‡â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–‡â–…â–…â–†â–…â–†â–†â–…â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–â–â–‚â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–„â–ˆâ–‚â–‚â–‚â–‚â–‡â–‚â–‚â–„â–…â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–‚â–‚â–‚â–…â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.1022\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 22\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.94524\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.1011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1350.21667\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.13607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 1066.20544\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.13538\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1624.20691\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.13675\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1609.23242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.01_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/xxqy6iw6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_222916-xxqy6iw6/logs\u001b[0m\n",
            "\n",
            "Deney 13/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 14/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.01_aug_False\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_224626-hcb9lfos\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.01_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/hcb9lfos\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - accuracy: 0.2747 - loss: 7.0207 - val_accuracy: 0.1242 - val_loss: 13.8126\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.4498 - loss: 8.3935 - val_accuracy: 0.2022 - val_loss: 7.9194\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.4924 - loss: 6.2858 - val_accuracy: 0.1956 - val_loss: 6.4222\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5547 - loss: 4.8259 - val_accuracy: 0.2330 - val_loss: 5.6896\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5888 - loss: 3.8463 - val_accuracy: 0.1615 - val_loss: 6.1637\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6474 - loss: 3.0614 - val_accuracy: 0.3264 - val_loss: 3.8581\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7052 - loss: 2.5458 - val_accuracy: 0.3132 - val_loss: 3.9564\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7574 - loss: 2.2831 - val_accuracy: 0.4549 - val_loss: 3.2953\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8083 - loss: 2.1041 - val_accuracy: 0.3374 - val_loss: 4.2347\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8572 - loss: 2.1516 - val_accuracy: 0.4802 - val_loss: 3.6333\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8598 - loss: 2.3387 - val_accuracy: 0.3659 - val_loss: 4.7334\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8851 - loss: 2.3795 - val_accuracy: 0.4066 - val_loss: 4.6671\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9081 - loss: 2.3372 - val_accuracy: 0.5121 - val_loss: 4.2365\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8942 - loss: 2.4722 - val_accuracy: 0.4857 - val_loss: 4.3931\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9148 - loss: 2.6229 - val_accuracy: 0.5033 - val_loss: 4.1504\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9296 - loss: 2.3616 - val_accuracy: 0.4593 - val_loss: 4.4678\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9210 - loss: 2.5365 - val_accuracy: 0.4747 - val_loss: 5.2638\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9104 - loss: 2.9025 - val_accuracy: 0.5044 - val_loss: 4.5214\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9265 - loss: 2.5047 - val_accuracy: 0.4154 - val_loss: 4.8931\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9357 - loss: 2.3675 - val_accuracy: 0.5209 - val_loss: 4.4395\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9284 - loss: 2.5918 - val_accuracy: 0.2055 - val_loss: 13.9795\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9153 - loss: 2.6571 - val_accuracy: 0.5022 - val_loss: 4.3864\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9434 - loss: 2.3295 - val_accuracy: 0.4637 - val_loss: 4.4688\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9409 - loss: 2.3652 - val_accuracy: 0.4626 - val_loss: 4.5239\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9414 - loss: 2.3379 - val_accuracy: 0.4374 - val_loss: 4.8610\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9400 - loss: 2.3207 - val_accuracy: 0.3824 - val_loss: 5.1535\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9446 - loss: 2.4320 - val_accuracy: 0.5253 - val_loss: 3.9806\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9479 - loss: 2.3595 - val_accuracy: 0.4143 - val_loss: 5.3963\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9400 - loss: 2.2960 - val_accuracy: 0.4055 - val_loss: 5.2554\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9424 - loss: 2.3564 - val_accuracy: 0.5286 - val_loss: 4.1358\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9502 - loss: 2.2596 - val_accuracy: 0.4769 - val_loss: 4.3966\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9436 - loss: 2.2803 - val_accuracy: 0.4264 - val_loss: 4.9879\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9323 - loss: 2.3525 - val_accuracy: 0.4615 - val_loss: 4.5858\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9536 - loss: 2.2444 - val_accuracy: 0.3648 - val_loss: 5.6716\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9511 - loss: 2.0530 - val_accuracy: 0.4582 - val_loss: 4.1394\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9488 - loss: 2.0620 - val_accuracy: 0.3868 - val_loss: 5.4621\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9416 - loss: 2.2479 - val_accuracy: 0.4516 - val_loss: 4.9662\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9415 - loss: 2.1597 - val_accuracy: 0.3857 - val_loss: 5.4549\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9392 - loss: 2.1789 - val_accuracy: 0.4824 - val_loss: 4.1206\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9438 - loss: 2.1625 - val_accuracy: 0.4286 - val_loss: 4.7229\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=8.4403, acc=0.3418, val_loss=13.8126, val_acc=0.1242\n",
            "Epoch 2: loss=7.8442, acc=0.4580, val_loss=7.9194, val_acc=0.2022\n",
            "Epoch 3: loss=5.9251, acc=0.5066, val_loss=6.4222, val_acc=0.1956\n",
            "Epoch 4: loss=4.6232, acc=0.5396, val_loss=5.6896, val_acc=0.2330\n",
            "Epoch 5: loss=3.6673, acc=0.5907, val_loss=6.1637, val_acc=0.1615\n",
            "Epoch 6: loss=2.9897, acc=0.6418, val_loss=3.8581, val_acc=0.3264\n",
            "Epoch 7: loss=2.5897, acc=0.6791, val_loss=3.9564, val_acc=0.3132\n",
            "Epoch 8: loss=2.3279, acc=0.7327, val_loss=3.2953, val_acc=0.4549\n",
            "Epoch 9: loss=2.1497, acc=0.7926, val_loss=4.2347, val_acc=0.3374\n",
            "Epoch 10: loss=2.2429, acc=0.8223, val_loss=3.6333, val_acc=0.4802\n",
            "Epoch 11: loss=2.3576, acc=0.8456, val_loss=4.7334, val_acc=0.3659\n",
            "Epoch 12: loss=2.4048, acc=0.8723, val_loss=4.6671, val_acc=0.4066\n",
            "Epoch 13: loss=2.3426, acc=0.8907, val_loss=4.2365, val_acc=0.5121\n",
            "Epoch 14: loss=2.5439, acc=0.8780, val_loss=4.3931, val_acc=0.4857\n",
            "Epoch 15: loss=2.5471, acc=0.9069, val_loss=4.1504, val_acc=0.5033\n",
            "Epoch 16: loss=2.4063, acc=0.9104, val_loss=4.4678, val_acc=0.4593\n",
            "Epoch 17: loss=2.6922, acc=0.8871, val_loss=5.2638, val_acc=0.4747\n",
            "Epoch 18: loss=2.7847, acc=0.9055, val_loss=4.5214, val_acc=0.5044\n",
            "Epoch 19: loss=2.4366, acc=0.9223, val_loss=4.8931, val_acc=0.4154\n",
            "Epoch 20: loss=2.4384, acc=0.9121, val_loss=4.4395, val_acc=0.5209\n",
            "Epoch 21: loss=2.6025, acc=0.9132, val_loss=13.9795, val_acc=0.2055\n",
            "Epoch 22: loss=2.6182, acc=0.9173, val_loss=4.3864, val_acc=0.5022\n",
            "Epoch 23: loss=2.3044, acc=0.9264, val_loss=4.4688, val_acc=0.4637\n",
            "Epoch 24: loss=2.3602, acc=0.9308, val_loss=4.5239, val_acc=0.4626\n",
            "Epoch 25: loss=2.3580, acc=0.9335, val_loss=4.8610, val_acc=0.4374\n",
            "Epoch 26: loss=2.3441, acc=0.9275, val_loss=5.1535, val_acc=0.3824\n",
            "Epoch 27: loss=2.4073, acc=0.9363, val_loss=3.9806, val_acc=0.5253\n",
            "Epoch 28: loss=2.3819, acc=0.9330, val_loss=5.3963, val_acc=0.4143\n",
            "Epoch 29: loss=2.3210, acc=0.9255, val_loss=5.2554, val_acc=0.4055\n",
            "Epoch 30: loss=2.3308, acc=0.9341, val_loss=4.1358, val_acc=0.5286\n",
            "Epoch 31: loss=2.2562, acc=0.9371, val_loss=4.3966, val_acc=0.4769\n",
            "Epoch 32: loss=2.3179, acc=0.9321, val_loss=4.9879, val_acc=0.4264\n",
            "Epoch 33: loss=2.3483, acc=0.9239, val_loss=4.5858, val_acc=0.4615\n",
            "Epoch 34: loss=2.1877, acc=0.9459, val_loss=5.6716, val_acc=0.3648\n",
            "Epoch 35: loss=2.0492, acc=0.9396, val_loss=4.1394, val_acc=0.4582\n",
            "Epoch 36: loss=2.1317, acc=0.9335, val_loss=5.4621, val_acc=0.3868\n",
            "Epoch 37: loss=2.2452, acc=0.9324, val_loss=4.9662, val_acc=0.4516\n",
            "Epoch 38: loss=2.1638, acc=0.9327, val_loss=5.4549, val_acc=0.3857\n",
            "Epoch 39: loss=2.2065, acc=0.9310, val_loss=4.1206, val_acc=0.4824\n",
            "Epoch 40: loss=2.1394, acc=0.9404, val_loss=4.7229, val_acc=0.4286\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.01_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 4.2947\n",
            "Accuracy: 0.4944\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 7.0522\n",
            "Accuracy: 0.2350\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 4.3925\n",
            "Accuracy: 0.4862\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–‚â–ƒâ–ƒâ–„â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–‚â–‚â–ƒâ–‚â–…â–„â–‡â–…â–‡â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–‚â–ˆâ–‡â–‡â–†â–…â–ˆâ–†â–†â–ˆâ–‡â–†â–‡â–…â–‡â–†â–‡â–†â–‡â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.94038\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.13941\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.42857\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 4.72289\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.23504\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 7.05223\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.49436\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 4.29467\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.48615\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 4.39249\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.01_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/hcb9lfos\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_224626-hcb9lfos/logs\u001b[0m\n",
            "\n",
            "Deney 14/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 15/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.001_aug_True\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_224819-jlz4helh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/jlz4helh\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 725ms/step - accuracy: 0.0993 - loss: 3.0315 - val_accuracy: 0.1099 - val_loss: 5.5307\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1100 - loss: 2.6751 - val_accuracy: 0.1099 - val_loss: 7.6324\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.0959 - loss: 2.7154 - val_accuracy: 0.1000 - val_loss: 14.0613\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 669ms/step - accuracy: 0.0935 - loss: 2.6631 - val_accuracy: 0.1000 - val_loss: 52.1621\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 667ms/step - accuracy: 0.1048 - loss: 2.6805 - val_accuracy: 0.1011 - val_loss: 80.2293\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 689ms/step - accuracy: 0.1082 - loss: 2.6337 - val_accuracy: 0.1341 - val_loss: 73.0024\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 676ms/step - accuracy: 0.1038 - loss: 2.6328 - val_accuracy: 0.1275 - val_loss: 83.7283\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 669ms/step - accuracy: 0.0928 - loss: 2.6144 - val_accuracy: 0.1231 - val_loss: 80.2062\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 668ms/step - accuracy: 0.1140 - loss: 2.6198 - val_accuracy: 0.1198 - val_loss: 203.9076\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 667ms/step - accuracy: 0.1108 - loss: 2.5852 - val_accuracy: 0.1132 - val_loss: 386.1777\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.0928 - loss: 2.5799 - val_accuracy: 0.1099 - val_loss: 496.7524\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.1039 - loss: 2.5980 - val_accuracy: 0.1066 - val_loss: 1342.8859\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.0951 - loss: 2.5704 - val_accuracy: 0.1198 - val_loss: 833.3548\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 688ms/step - accuracy: 0.1143 - loss: 2.5691 - val_accuracy: 0.1692 - val_loss: 470.6745\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 670ms/step - accuracy: 0.1036 - loss: 2.5974 - val_accuracy: 0.1308 - val_loss: 538.1743\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 694ms/step - accuracy: 0.1018 - loss: 2.5782 - val_accuracy: 0.1890 - val_loss: 769.6666\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 692ms/step - accuracy: 0.1039 - loss: 2.5855 - val_accuracy: 0.2099 - val_loss: 226.9107\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 671ms/step - accuracy: 0.1139 - loss: 2.5638 - val_accuracy: 0.1989 - val_loss: 215.4046\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.0920 - loss: 2.5721 - val_accuracy: 0.1440 - val_loss: 814.5422\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.1171 - loss: 2.5245 - val_accuracy: 0.1121 - val_loss: 952.8439\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 660ms/step - accuracy: 0.1137 - loss: 2.5186 - val_accuracy: 0.1275 - val_loss: 661.0103\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.0996 - loss: 2.5179 - val_accuracy: 0.1319 - val_loss: 806.5646\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.0914 - loss: 2.5152 - val_accuracy: 0.1011 - val_loss: 978.8368\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.0941 - loss: 2.5026 - val_accuracy: 0.1374 - val_loss: 1137.5684\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.1038 - loss: 2.5001 - val_accuracy: 0.1000 - val_loss: 1473.5157\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 661ms/step - accuracy: 0.1071 - loss: 2.4734 - val_accuracy: 0.1154 - val_loss: 2765.7432\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1084 - loss: 2.4776 - val_accuracy: 0.0989 - val_loss: 1942.6571\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.8457, acc=0.0967, val_loss=5.5307, val_acc=0.1099\n",
            "Epoch 2: loss=2.6594, acc=0.1071, val_loss=7.6324, val_acc=0.1099\n",
            "Epoch 3: loss=2.6876, acc=0.0984, val_loss=14.0613, val_acc=0.1000\n",
            "Epoch 4: loss=2.6538, acc=0.1027, val_loss=52.1621, val_acc=0.1000\n",
            "Epoch 5: loss=2.6748, acc=0.1063, val_loss=80.2293, val_acc=0.1011\n",
            "Epoch 6: loss=2.6485, acc=0.1091, val_loss=73.0024, val_acc=0.1341\n",
            "Epoch 7: loss=2.6504, acc=0.1058, val_loss=83.7283, val_acc=0.1275\n",
            "Epoch 8: loss=2.6223, acc=0.1038, val_loss=80.2062, val_acc=0.1231\n",
            "Epoch 9: loss=2.6059, acc=0.1071, val_loss=203.9076, val_acc=0.1198\n",
            "Epoch 10: loss=2.5737, acc=0.1104, val_loss=386.1777, val_acc=0.1132\n",
            "Epoch 11: loss=2.5755, acc=0.1019, val_loss=496.7524, val_acc=0.1099\n",
            "Epoch 12: loss=2.6028, acc=0.0989, val_loss=1342.8859, val_acc=0.1066\n",
            "Epoch 13: loss=2.5824, acc=0.0959, val_loss=833.3548, val_acc=0.1198\n",
            "Epoch 14: loss=2.5852, acc=0.1063, val_loss=470.6745, val_acc=0.1692\n",
            "Epoch 15: loss=2.5995, acc=0.1047, val_loss=538.1743, val_acc=0.1308\n",
            "Epoch 16: loss=2.5803, acc=0.1005, val_loss=769.6666, val_acc=0.1890\n",
            "Epoch 17: loss=2.5994, acc=0.1027, val_loss=226.9107, val_acc=0.2099\n",
            "Epoch 18: loss=2.5603, acc=0.1113, val_loss=215.4046, val_acc=0.1989\n",
            "Epoch 19: loss=2.5694, acc=0.0986, val_loss=814.5422, val_acc=0.1440\n",
            "Epoch 20: loss=2.5407, acc=0.1110, val_loss=952.8439, val_acc=0.1121\n",
            "Epoch 21: loss=2.5192, acc=0.1102, val_loss=661.0103, val_acc=0.1275\n",
            "Epoch 22: loss=2.5133, acc=0.0953, val_loss=806.5646, val_acc=0.1319\n",
            "Epoch 23: loss=2.4983, acc=0.0970, val_loss=978.8368, val_acc=0.1011\n",
            "Epoch 24: loss=2.4997, acc=0.1022, val_loss=1137.5684, val_acc=0.1374\n",
            "Epoch 25: loss=2.4919, acc=0.1066, val_loss=1473.5157, val_acc=0.1000\n",
            "Epoch 26: loss=2.4816, acc=0.1082, val_loss=2765.7432, val_acc=0.1154\n",
            "Epoch 27: loss=2.4840, acc=0.1096, val_loss=1942.6571, val_acc=0.0989\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 233.2690\n",
            "Accuracy: 0.2036\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 1227.3999\n",
            "Accuracy: 0.1600\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 210.8924\n",
            "Accuracy: 0.1884\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–‚â–†â–‚â–„â–†â–‡â–†â–…â–†â–ˆâ–„â–ƒâ–â–†â–…â–ƒâ–„â–ˆâ–‚â–ˆâ–ˆâ–â–‚â–„â–†â–‡â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–…â–„â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–‚â–‚â–â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–…â–ƒâ–‡â–ˆâ–‡â–„â–‚â–ƒâ–ƒâ–â–ƒâ–â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ˆâ–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10962\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 26\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.48396\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.0989\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1942.6571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 1227.3999\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.20359\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 233.26904\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.18838\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 210.8924\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/jlz4helh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_224819-jlz4helh/logs\u001b[0m\n",
            "\n",
            "Deney 15/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 16/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.001_aug_False\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_230819-afs5ou3r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/afs5ou3r\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - accuracy: 0.3437 - loss: 2.5461 - val_accuracy: 0.1154 - val_loss: 3.5896\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.5708 - loss: 1.4194 - val_accuracy: 0.1484 - val_loss: 3.5127\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6750 - loss: 1.1551 - val_accuracy: 0.2692 - val_loss: 3.0331\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7708 - loss: 0.9236 - val_accuracy: 0.2154 - val_loss: 3.1850\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8734 - loss: 0.6392 - val_accuracy: 0.2637 - val_loss: 3.0564\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9321 - loss: 0.4699 - val_accuracy: 0.2956 - val_loss: 2.5575\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9600 - loss: 0.3983 - val_accuracy: 0.3978 - val_loss: 2.2443\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9922 - loss: 0.3057 - val_accuracy: 0.4747 - val_loss: 1.9894\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9949 - loss: 0.2681 - val_accuracy: 0.5648 - val_loss: 1.5794\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2329 - val_accuracy: 0.5901 - val_loss: 1.5332\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9999 - loss: 0.2134 - val_accuracy: 0.5967 - val_loss: 1.5250\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9988 - loss: 0.1963 - val_accuracy: 0.6000 - val_loss: 1.4517\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1761 - val_accuracy: 0.6297 - val_loss: 1.4153\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1595 - val_accuracy: 0.6264 - val_loss: 1.4470\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9996 - loss: 0.1481 - val_accuracy: 0.5835 - val_loss: 1.7121\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9970 - loss: 0.1568 - val_accuracy: 0.5264 - val_loss: 2.2808\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9469 - loss: 0.3539 - val_accuracy: 0.3407 - val_loss: 5.2137\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9160 - loss: 0.5737 - val_accuracy: 0.3659 - val_loss: 3.5923\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9642 - loss: 0.5245 - val_accuracy: 0.5857 - val_loss: 2.1881\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9956 - loss: 0.4297 - val_accuracy: 0.5769 - val_loss: 1.8549\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 0.3690 - val_accuracy: 0.6198 - val_loss: 1.7056\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.3233 - val_accuracy: 0.6418 - val_loss: 1.5750\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.2841 - val_accuracy: 0.6330 - val_loss: 1.5215\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2499 - val_accuracy: 0.6527 - val_loss: 1.5317\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.2200 - val_accuracy: 0.6242 - val_loss: 1.6811\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.2005 - val_accuracy: 0.6396 - val_loss: 1.4900\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1726 - val_accuracy: 0.6462 - val_loss: 1.4339\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1519 - val_accuracy: 0.6505 - val_loss: 1.4016\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1338 - val_accuracy: 0.6440 - val_loss: 1.3974\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1180 - val_accuracy: 0.6604 - val_loss: 1.3950\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1040 - val_accuracy: 0.6593 - val_loss: 1.3821\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0917 - val_accuracy: 0.6582 - val_loss: 1.3622\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0810 - val_accuracy: 0.6440 - val_loss: 1.4037\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0718 - val_accuracy: 0.6538 - val_loss: 1.3472\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.6582 - val_loss: 1.3372\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.6527 - val_loss: 1.3486\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 0.6429 - val_loss: 1.3636\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0548 - val_accuracy: 0.3286 - val_loss: 8.8641\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6289 - loss: 1.6704 - val_accuracy: 0.4220 - val_loss: 5.2675\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9059 - loss: 1.1639 - val_accuracy: 0.5429 - val_loss: 2.5290\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.0471, acc=0.4195, val_loss=3.5896, val_acc=0.1154\n",
            "Epoch 2: loss=1.3919, acc=0.5852, val_loss=3.5127, val_acc=0.1484\n",
            "Epoch 3: loss=1.1594, acc=0.6717, val_loss=3.0331, val_acc=0.2692\n",
            "Epoch 4: loss=0.9274, acc=0.7654, val_loss=3.1850, val_acc=0.2154\n",
            "Epoch 5: loss=0.6407, acc=0.8717, val_loss=3.0564, val_acc=0.2637\n",
            "Epoch 6: loss=0.4718, acc=0.9308, val_loss=2.5575, val_acc=0.2956\n",
            "Epoch 7: loss=0.3884, acc=0.9646, val_loss=2.2443, val_acc=0.3978\n",
            "Epoch 8: loss=0.3003, acc=0.9929, val_loss=1.9894, val_acc=0.4747\n",
            "Epoch 9: loss=0.2610, acc=0.9973, val_loss=1.5794, val_acc=0.5648\n",
            "Epoch 10: loss=0.2308, acc=0.9997, val_loss=1.5332, val_acc=0.5901\n",
            "Epoch 11: loss=0.2091, acc=0.9995, val_loss=1.5250, val_acc=0.5967\n",
            "Epoch 12: loss=0.1916, acc=0.9995, val_loss=1.4517, val_acc=0.6000\n",
            "Epoch 13: loss=0.1719, acc=1.0000, val_loss=1.4153, val_acc=0.6297\n",
            "Epoch 14: loss=0.1563, acc=1.0000, val_loss=1.4470, val_acc=0.6264\n",
            "Epoch 15: loss=0.1489, acc=0.9992, val_loss=1.7121, val_acc=0.5835\n",
            "Epoch 16: loss=0.1856, acc=0.9926, val_loss=2.2808, val_acc=0.5264\n",
            "Epoch 17: loss=0.4811, acc=0.9107, val_loss=5.2137, val_acc=0.3407\n",
            "Epoch 18: loss=0.6318, acc=0.9022, val_loss=3.5923, val_acc=0.3659\n",
            "Epoch 19: loss=0.5166, acc=0.9681, val_loss=2.1881, val_acc=0.5857\n",
            "Epoch 20: loss=0.4154, acc=0.9962, val_loss=1.8549, val_acc=0.5769\n",
            "Epoch 21: loss=0.3591, acc=0.9992, val_loss=1.7056, val_acc=0.6198\n",
            "Epoch 22: loss=0.3132, acc=1.0000, val_loss=1.5750, val_acc=0.6418\n",
            "Epoch 23: loss=0.2757, acc=1.0000, val_loss=1.5215, val_acc=0.6330\n",
            "Epoch 24: loss=0.2424, acc=1.0000, val_loss=1.5317, val_acc=0.6527\n",
            "Epoch 25: loss=0.2144, acc=0.9995, val_loss=1.6811, val_acc=0.6242\n",
            "Epoch 26: loss=0.1927, acc=0.9995, val_loss=1.4900, val_acc=0.6396\n",
            "Epoch 27: loss=0.1674, acc=1.0000, val_loss=1.4339, val_acc=0.6462\n",
            "Epoch 28: loss=0.1473, acc=1.0000, val_loss=1.4016, val_acc=0.6505\n",
            "Epoch 29: loss=0.1300, acc=1.0000, val_loss=1.3974, val_acc=0.6440\n",
            "Epoch 30: loss=0.1145, acc=1.0000, val_loss=1.3950, val_acc=0.6604\n",
            "Epoch 31: loss=0.1008, acc=1.0000, val_loss=1.3821, val_acc=0.6593\n",
            "Epoch 32: loss=0.0890, acc=1.0000, val_loss=1.3622, val_acc=0.6582\n",
            "Epoch 33: loss=0.0787, acc=1.0000, val_loss=1.4037, val_acc=0.6440\n",
            "Epoch 34: loss=0.0698, acc=1.0000, val_loss=1.3472, val_acc=0.6538\n",
            "Epoch 35: loss=0.0621, acc=1.0000, val_loss=1.3372, val_acc=0.6582\n",
            "Epoch 36: loss=0.0555, acc=1.0000, val_loss=1.3486, val_acc=0.6527\n",
            "Epoch 37: loss=0.0498, acc=1.0000, val_loss=1.3636, val_acc=0.6429\n",
            "Epoch 38: loss=0.1424, acc=0.9755, val_loss=8.8641, val_acc=0.3286\n",
            "Epoch 39: loss=1.8319, acc=0.6341, val_loss=5.2675, val_acc=0.4220\n",
            "Epoch 40: loss=1.0898, acc=0.9245, val_loss=2.5290, val_acc=0.5429\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.4452\n",
            "Accuracy: 0.6159\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.7896\n",
            "Accuracy: 0.2591\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.4837\n",
            "Accuracy: 0.6074\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–ƒâ–‚â–ƒâ–ƒâ–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–†â–„â–„â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–…â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–…â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–…â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.92445\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 1.08983\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.54286\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 2.529\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.25915\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.78959\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.6159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.44521\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.60735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.48371\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/afs5ou3r\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_230819-afs5ou3r/logs\u001b[0m\n",
            "\n",
            "Deney 16/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 17/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.0001_aug_True\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_231017-eq3jg42m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.0001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/eq3jg42m\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 724ms/step - accuracy: 0.0911 - loss: 2.9512 - val_accuracy: 0.1055 - val_loss: 2.8379\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 666ms/step - accuracy: 0.0993 - loss: 2.6278 - val_accuracy: 0.1011 - val_loss: 2.9911\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 667ms/step - accuracy: 0.1010 - loss: 2.5816 - val_accuracy: 0.1000 - val_loss: 3.7711\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 689ms/step - accuracy: 0.1016 - loss: 2.6077 - val_accuracy: 0.1275 - val_loss: 4.5410\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 689ms/step - accuracy: 0.0972 - loss: 2.5883 - val_accuracy: 0.2429 - val_loss: 6.6085\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 667ms/step - accuracy: 0.1051 - loss: 2.5887 - val_accuracy: 0.1363 - val_loss: 24.5164\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1083 - loss: 2.5675 - val_accuracy: 0.1934 - val_loss: 28.9658\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.1078 - loss: 2.5386 - val_accuracy: 0.1033 - val_loss: 141.5677\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.1151 - loss: 2.5490 - val_accuracy: 0.1132 - val_loss: 287.6620\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.1205 - loss: 2.5562 - val_accuracy: 0.1000 - val_loss: 817.0196\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.1269 - loss: 2.5332 - val_accuracy: 0.1736 - val_loss: 521.0299\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 665ms/step - accuracy: 0.1112 - loss: 2.5259 - val_accuracy: 0.0989 - val_loss: 1495.9153\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 663ms/step - accuracy: 0.1054 - loss: 2.5416 - val_accuracy: 0.1033 - val_loss: 2004.0638\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 662ms/step - accuracy: 0.1194 - loss: 2.5219 - val_accuracy: 0.1308 - val_loss: 1919.5933\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 664ms/step - accuracy: 0.1032 - loss: 2.5342 - val_accuracy: 0.1000 - val_loss: 4225.9614\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.7989, acc=0.0981, val_loss=2.8379, val_acc=0.1055\n",
            "Epoch 2: loss=2.6283, acc=0.1055, val_loss=2.9911, val_acc=0.1011\n",
            "Epoch 3: loss=2.6079, acc=0.1025, val_loss=3.7711, val_acc=0.1000\n",
            "Epoch 4: loss=2.5692, acc=0.1038, val_loss=4.5410, val_acc=0.1275\n",
            "Epoch 5: loss=2.5827, acc=0.1011, val_loss=6.6085, val_acc=0.2429\n",
            "Epoch 6: loss=2.5606, acc=0.0986, val_loss=24.5164, val_acc=0.1363\n",
            "Epoch 7: loss=2.5506, acc=0.1113, val_loss=28.9658, val_acc=0.1934\n",
            "Epoch 8: loss=2.5506, acc=0.1104, val_loss=141.5677, val_acc=0.1033\n",
            "Epoch 9: loss=2.5547, acc=0.1107, val_loss=287.6620, val_acc=0.1132\n",
            "Epoch 10: loss=2.5757, acc=0.1113, val_loss=817.0196, val_acc=0.1000\n",
            "Epoch 11: loss=2.5148, acc=0.1214, val_loss=521.0299, val_acc=0.1736\n",
            "Epoch 12: loss=2.5224, acc=0.1019, val_loss=1495.9153, val_acc=0.0989\n",
            "Epoch 13: loss=2.5238, acc=0.1069, val_loss=2004.0638, val_acc=0.1033\n",
            "Epoch 14: loss=2.5246, acc=0.1063, val_loss=1919.5933, val_acc=0.1308\n",
            "Epoch 15: loss=2.5273, acc=0.0981, val_loss=4225.9614, val_acc=0.1000\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.0001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 6.7466\n",
            "Accuracy: 0.2333\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 5.2006\n",
            "Accuracy: 0.1774\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 6.8568\n",
            "Accuracy: 0.2256\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–‚â–ƒâ–‚â–â–…â–…â–…â–…â–ˆâ–‚â–„â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–†â–‡â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–â–‚â–ˆâ–ƒâ–†â–â–‚â–â–…â–â–â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–„â–„â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.09808\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.52734\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 4225.96143\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.17744\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 5.20065\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.23333\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 6.74657\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.22564\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 6.85682\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.0001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/eq3jg42m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_231017-eq3jg42m/logs\u001b[0m\n",
            "\n",
            "Deney 17/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 18/36 ====================\n",
            "Deney AdÄ±: exp_size_224_act_elu_lr_0.0001_aug_False\n",
            "Input Size: 224\n",
            "Activation: elu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232133-os3rpxql\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_224_act_elu_lr_0.0001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/os3rpxql\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m224\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m112\u001b[0m, \u001b[32m64\u001b[0m)        â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m56\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m28\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m100352\u001b[0m)              â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚      \u001b[32m25,690,368\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m25,788,106\u001b[0m (98.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m25,787,146\u001b[0m (98.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.3675 - loss: 2.4569 - val_accuracy: 0.1231 - val_loss: 2.6351\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6505 - loss: 1.1479 - val_accuracy: 0.1011 - val_loss: 3.0448\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.8402 - loss: 0.6164 - val_accuracy: 0.1000 - val_loss: 3.5233\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9485 - loss: 0.2942 - val_accuracy: 0.1154 - val_loss: 3.2290\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9892 - loss: 0.1493 - val_accuracy: 0.2593 - val_loss: 2.2800\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9952 - loss: 0.1075 - val_accuracy: 0.2341 - val_loss: 2.4763\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9997 - loss: 0.0836 - val_accuracy: 0.3890 - val_loss: 1.9049\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0766 - val_accuracy: 0.5121 - val_loss: 1.6311\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0721 - val_accuracy: 0.5341 - val_loss: 1.5294\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 0.5341 - val_loss: 1.5335\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0701 - val_accuracy: 0.5582 - val_loss: 1.4966\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 0.5692 - val_loss: 1.4962\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0688 - val_accuracy: 0.5736 - val_loss: 1.5113\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0682 - val_accuracy: 0.5626 - val_loss: 1.5229\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0682 - val_accuracy: 0.5637 - val_loss: 1.5522\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 0.5747 - val_loss: 1.5364\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.5725 - val_loss: 1.5508\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0666 - val_accuracy: 0.5769 - val_loss: 1.5515\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0665 - val_accuracy: 0.5736 - val_loss: 1.5504\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0660 - val_accuracy: 0.5670 - val_loss: 1.5680\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 0.5659 - val_loss: 1.5808\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0652 - val_accuracy: 0.5703 - val_loss: 1.5604\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0649 - val_accuracy: 0.5791 - val_loss: 1.5570\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 0.5703 - val_loss: 1.5710\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0642 - val_accuracy: 0.5626 - val_loss: 1.5722\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.5681 - val_loss: 1.5825\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 0.5670 - val_loss: 1.5797\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 0.5703 - val_loss: 1.5831\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0627 - val_accuracy: 0.5692 - val_loss: 1.5766\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0624 - val_accuracy: 0.5626 - val_loss: 1.5891\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0620 - val_accuracy: 0.5648 - val_loss: 1.5946\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0616 - val_accuracy: 0.5659 - val_loss: 1.5972\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0612 - val_accuracy: 0.5659 - val_loss: 1.5843\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.9830, acc=0.4288, val_loss=2.6351, val_acc=0.1231\n",
            "Epoch 2: loss=1.0701, acc=0.6736, val_loss=3.0448, val_acc=0.1011\n",
            "Epoch 3: loss=0.6129, acc=0.8346, val_loss=3.5233, val_acc=0.1000\n",
            "Epoch 4: loss=0.2845, acc=0.9492, val_loss=3.2290, val_acc=0.1154\n",
            "Epoch 5: loss=0.1459, acc=0.9887, val_loss=2.2800, val_acc=0.2593\n",
            "Epoch 6: loss=0.1019, acc=0.9962, val_loss=2.4763, val_acc=0.2341\n",
            "Epoch 7: loss=0.0830, acc=0.9989, val_loss=1.9049, val_acc=0.3890\n",
            "Epoch 8: loss=0.0759, acc=1.0000, val_loss=1.6311, val_acc=0.5121\n",
            "Epoch 9: loss=0.0722, acc=1.0000, val_loss=1.5294, val_acc=0.5341\n",
            "Epoch 10: loss=0.0715, acc=1.0000, val_loss=1.5335, val_acc=0.5341\n",
            "Epoch 11: loss=0.0703, acc=1.0000, val_loss=1.4966, val_acc=0.5582\n",
            "Epoch 12: loss=0.0695, acc=1.0000, val_loss=1.4962, val_acc=0.5692\n",
            "Epoch 13: loss=0.0687, acc=1.0000, val_loss=1.5113, val_acc=0.5736\n",
            "Epoch 14: loss=0.0681, acc=1.0000, val_loss=1.5229, val_acc=0.5626\n",
            "Epoch 15: loss=0.0680, acc=1.0000, val_loss=1.5522, val_acc=0.5637\n",
            "Epoch 16: loss=0.0673, acc=1.0000, val_loss=1.5364, val_acc=0.5747\n",
            "Epoch 17: loss=0.0669, acc=1.0000, val_loss=1.5508, val_acc=0.5725\n",
            "Epoch 18: loss=0.0666, acc=1.0000, val_loss=1.5515, val_acc=0.5769\n",
            "Epoch 19: loss=0.0664, acc=1.0000, val_loss=1.5504, val_acc=0.5736\n",
            "Epoch 20: loss=0.0659, acc=1.0000, val_loss=1.5680, val_acc=0.5670\n",
            "Epoch 21: loss=0.0656, acc=1.0000, val_loss=1.5808, val_acc=0.5659\n",
            "Epoch 22: loss=0.0652, acc=1.0000, val_loss=1.5604, val_acc=0.5703\n",
            "Epoch 23: loss=0.0649, acc=1.0000, val_loss=1.5570, val_acc=0.5791\n",
            "Epoch 24: loss=0.0645, acc=1.0000, val_loss=1.5710, val_acc=0.5703\n",
            "Epoch 25: loss=0.0641, acc=1.0000, val_loss=1.5722, val_acc=0.5626\n",
            "Epoch 26: loss=0.0638, acc=1.0000, val_loss=1.5825, val_acc=0.5681\n",
            "Epoch 27: loss=0.0634, acc=1.0000, val_loss=1.5797, val_acc=0.5670\n",
            "Epoch 28: loss=0.0631, acc=1.0000, val_loss=1.5831, val_acc=0.5703\n",
            "Epoch 29: loss=0.0627, acc=1.0000, val_loss=1.5766, val_acc=0.5692\n",
            "Epoch 30: loss=0.0623, acc=1.0000, val_loss=1.5891, val_acc=0.5626\n",
            "Epoch 31: loss=0.0619, acc=1.0000, val_loss=1.5946, val_acc=0.5648\n",
            "Epoch 32: loss=0.0615, acc=1.0000, val_loss=1.5972, val_acc=0.5659\n",
            "Epoch 33: loss=0.0611, acc=1.0000, val_loss=1.5843, val_acc=0.5659\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_224_act_elu_lr_0.0001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.6493\n",
            "Accuracy: 0.5600\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.9237\n",
            "Accuracy: 0.2571\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.7016\n",
            "Accuracy: 0.5508\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–â–â–ƒâ–ƒâ–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–…â–†â–ˆâ–‡â–„â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.06109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.56593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.58432\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.25709\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.92373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.56\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.64927\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.55077\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.7016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_224_act_elu_lr_0.0001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/os3rpxql\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232133-os3rpxql/logs\u001b[0m\n",
            "\n",
            "Deney 18/36 tamamlandÄ±.\n",
            "\n",
            "Input size 128 iÃ§in dataset hazÄ±rlanÄ±yor...\n",
            "--------------------TRAIN Veri Seti EÄŸitim iÃ§in HazÄ±rlanÄ±yor. ## input_size: 128--------------------\n",
            "Found 3640 files belonging to 10 classes.\n",
            "--------------------VAL Veri Seti EÄŸitim iÃ§in HazÄ±rlanÄ±yor. ## input_size: 128--------------------\n",
            "Found 910 files belonging to 10 classes.\n",
            "--------------------TEST Veri Seti EÄŸitim iÃ§in HazÄ±rlanÄ±yor. ## input_size: 128--------------------\n",
            "Found 1950 files belonging to 10 classes.\n",
            "--------------------TEST_MANIPULATED Veri Seti EÄŸitim iÃ§in HazÄ±rlanÄ±yor. ## input_size: 128--------------------\n",
            "Found 5850 files belonging to 10 classes.\n",
            "--------------------TEST_WB Veri Seti EÄŸitim iÃ§in HazÄ±rlanÄ±yor. ## input_size: 128--------------------\n",
            "Found 5850 files belonging to 10 classes.\n",
            "\n",
            "Toplam deney sayÄ±sÄ±: 36\n",
            "\n",
            "Dataset'ler numpy array'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...\n",
            "\n",
            "Veri seti kontrolleri:\n",
            "Train veri seti: 3640 Ã¶rnek\n",
            "Validation veri seti: 910 Ã¶rnek\n",
            "Test veri seti: 1950 Ã¶rnek\n",
            "Test manipÃ¼le veri seti: 5850 Ã¶rnek\n",
            "Test renk sabitliÄŸi veri seti: 5850 Ã¶rnek\n",
            "\n",
            "==================== Deney 19/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.01_aug_True\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232357-93r63mi8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.01_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/93r63mi8\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 360ms/step - accuracy: 0.1039 - loss: 3.5976 - val_accuracy: 0.1099 - val_loss: 63.8389\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.0978 - loss: 3.7869 - val_accuracy: 0.1187 - val_loss: 44.7359\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.0981 - loss: 3.5891 - val_accuracy: 0.0912 - val_loss: 50.9654\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1034 - loss: 3.3868 - val_accuracy: 0.1022 - val_loss: 107.5634\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1082 - loss: 3.2219 - val_accuracy: 0.1000 - val_loss: 402.7549\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0945 - loss: 3.3105 - val_accuracy: 0.1000 - val_loss: 242.7094\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0938 - loss: 3.3346 - val_accuracy: 0.1000 - val_loss: 324.6706\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1054 - loss: 3.4075 - val_accuracy: 0.1132 - val_loss: 143.4054\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1172 - loss: 3.1434 - val_accuracy: 0.1209 - val_loss: 131.9969\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1066 - loss: 3.2611 - val_accuracy: 0.1044 - val_loss: 203.4245\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0921 - loss: 3.4286 - val_accuracy: 0.1088 - val_loss: 193.9398\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1034 - loss: 3.1999 - val_accuracy: 0.1000 - val_loss: 762.3158\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1033 - loss: 3.3231 - val_accuracy: 0.1000 - val_loss: 739.0614\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0964 - loss: 3.2760 - val_accuracy: 0.1154 - val_loss: 307.0553\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1054 - loss: 3.3572 - val_accuracy: 0.1011 - val_loss: 155.2352\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1004 - loss: 3.2747 - val_accuracy: 0.1000 - val_loss: 603.8552\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0951 - loss: 3.3362 - val_accuracy: 0.1000 - val_loss: 480063.1250\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1110 - loss: 3.4572 - val_accuracy: 0.1000 - val_loss: 93.5751\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0956 - loss: 3.6136 - val_accuracy: 0.1033 - val_loss: 146.4654\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=3.8763, acc=0.1003, val_loss=63.8389, val_acc=0.1099\n",
            "Epoch 2: loss=3.7227, acc=0.0975, val_loss=44.7359, val_acc=0.1187\n",
            "Epoch 3: loss=3.5130, acc=0.1003, val_loss=50.9654, val_acc=0.0912\n",
            "Epoch 4: loss=3.3274, acc=0.1074, val_loss=107.5634, val_acc=0.1022\n",
            "Epoch 5: loss=3.2560, acc=0.1027, val_loss=402.7549, val_acc=0.1000\n",
            "Epoch 6: loss=3.2938, acc=0.1011, val_loss=242.7094, val_acc=0.1000\n",
            "Epoch 7: loss=3.4016, acc=0.0918, val_loss=324.6706, val_acc=0.1000\n",
            "Epoch 8: loss=3.3364, acc=0.1044, val_loss=143.4054, val_acc=0.1132\n",
            "Epoch 9: loss=3.1747, acc=0.1074, val_loss=131.9969, val_acc=0.1209\n",
            "Epoch 10: loss=3.3213, acc=0.1014, val_loss=203.4245, val_acc=0.1044\n",
            "Epoch 11: loss=3.4033, acc=0.0953, val_loss=193.9398, val_acc=0.1088\n",
            "Epoch 12: loss=3.2237, acc=0.1027, val_loss=762.3158, val_acc=0.1000\n",
            "Epoch 13: loss=3.3013, acc=0.1005, val_loss=739.0614, val_acc=0.1000\n",
            "Epoch 14: loss=3.2801, acc=0.1016, val_loss=307.0553, val_acc=0.1154\n",
            "Epoch 15: loss=3.3635, acc=0.1025, val_loss=155.2352, val_acc=0.1011\n",
            "Epoch 16: loss=3.2617, acc=0.0986, val_loss=603.8552, val_acc=0.1000\n",
            "Epoch 17: loss=3.3351, acc=0.0978, val_loss=480063.1250, val_acc=0.1000\n",
            "Epoch 18: loss=3.5809, acc=0.1041, val_loss=93.5751, val_acc=0.1000\n",
            "Epoch 19: loss=3.5924, acc=0.1025, val_loss=146.4654, val_acc=0.1033\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.01_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 133.3447\n",
            "Accuracy: 0.1292\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 99.6485\n",
            "Accuracy: 0.1176\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 132.1634\n",
            "Accuracy: 0.1215\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–…â–„â–…â–ˆâ–†â–…â–â–‡â–ˆâ–…â–ƒâ–†â–…â–…â–†â–„â–„â–‡â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–†â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–…â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–…â–‡â–â–„â–ƒâ–ƒâ–ƒâ–†â–ˆâ–„â–…â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10247\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 3.59245\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.1033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 146.46541\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.11761\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 99.64848\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.12923\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 133.34465\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.12154\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 132.16339\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.01_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/93r63mi8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232357-93r63mi8/logs\u001b[0m\n",
            "\n",
            "Deney 19/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 20/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.01_aug_False\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232928-un7m6c34\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.01_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/un7m6c34\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 94ms/step - accuracy: 0.3160 - loss: 3.9002 - val_accuracy: 0.1780 - val_loss: 7.1507\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5122 - loss: 3.8394 - val_accuracy: 0.2495 - val_loss: 4.4717\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5582 - loss: 3.1267 - val_accuracy: 0.2692 - val_loss: 4.8521\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6265 - loss: 2.6733 - val_accuracy: 0.3659 - val_loss: 3.4918\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7227 - loss: 2.1505 - val_accuracy: 0.3209 - val_loss: 3.7333\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7741 - loss: 1.8986 - val_accuracy: 0.3736 - val_loss: 3.4827\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8062 - loss: 1.8349 - val_accuracy: 0.3923 - val_loss: 3.4631\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8506 - loss: 1.7784 - val_accuracy: 0.4407 - val_loss: 3.4280\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8716 - loss: 1.7629 - val_accuracy: 0.4879 - val_loss: 3.4036\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8980 - loss: 1.8305 - val_accuracy: 0.4637 - val_loss: 3.5223\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9030 - loss: 1.8632 - val_accuracy: 0.5000 - val_loss: 3.4875\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9067 - loss: 1.9247 - val_accuracy: 0.4242 - val_loss: 4.6111\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8983 - loss: 2.1294 - val_accuracy: 0.3297 - val_loss: 5.9090\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9216 - loss: 1.9953 - val_accuracy: 0.3835 - val_loss: 4.2948\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9273 - loss: 1.9097 - val_accuracy: 0.4835 - val_loss: 3.8032\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9242 - loss: 1.8668 - val_accuracy: 0.5571 - val_loss: 3.5291\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9237 - loss: 2.0129 - val_accuracy: 0.5242 - val_loss: 4.1789\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9198 - loss: 2.0829 - val_accuracy: 0.4571 - val_loss: 4.5689\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9225 - loss: 2.1445 - val_accuracy: 0.5066 - val_loss: 4.5833\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9404 - loss: 1.9571 - val_accuracy: 0.4978 - val_loss: 3.8989\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9350 - loss: 1.9170 - val_accuracy: 0.3879 - val_loss: 4.9709\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9102 - loss: 2.1568 - val_accuracy: 0.4868 - val_loss: 4.4239\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9366 - loss: 2.0984 - val_accuracy: 0.5308 - val_loss: 3.8989\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 1.8098 - val_accuracy: 0.5363 - val_loss: 3.4736\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9579 - loss: 1.6794 - val_accuracy: 0.4824 - val_loss: 4.0614\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 1.9037 - val_accuracy: 0.5176 - val_loss: 4.1258\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=4.1609, acc=0.3764, val_loss=7.1507, val_acc=0.1780\n",
            "Epoch 2: loss=3.7054, acc=0.5093, val_loss=4.4717, val_acc=0.2495\n",
            "Epoch 3: loss=3.0305, acc=0.5692, val_loss=4.8521, val_acc=0.2692\n",
            "Epoch 4: loss=2.6301, acc=0.6181, val_loss=3.4918, val_acc=0.3659\n",
            "Epoch 5: loss=2.1686, acc=0.7000, val_loss=3.7333, val_acc=0.3209\n",
            "Epoch 6: loss=1.9491, acc=0.7541, val_loss=3.4827, val_acc=0.3736\n",
            "Epoch 7: loss=1.8958, acc=0.7838, val_loss=3.4631, val_acc=0.3923\n",
            "Epoch 8: loss=1.7941, acc=0.8368, val_loss=3.4280, val_acc=0.4407\n",
            "Epoch 9: loss=1.8376, acc=0.8511, val_loss=3.4036, val_acc=0.4879\n",
            "Epoch 10: loss=1.8783, acc=0.8791, val_loss=3.5223, val_acc=0.4637\n",
            "Epoch 11: loss=1.8901, acc=0.8901, val_loss=3.4875, val_acc=0.5000\n",
            "Epoch 12: loss=2.0131, acc=0.8805, val_loss=4.6111, val_acc=0.4242\n",
            "Epoch 13: loss=2.1491, acc=0.8885, val_loss=5.9090, val_acc=0.3297\n",
            "Epoch 14: loss=2.0098, acc=0.9077, val_loss=4.2948, val_acc=0.3835\n",
            "Epoch 15: loss=1.9118, acc=0.9176, val_loss=3.8032, val_acc=0.4835\n",
            "Epoch 16: loss=1.9457, acc=0.9066, val_loss=3.5291, val_acc=0.5571\n",
            "Epoch 17: loss=2.0606, acc=0.9085, val_loss=4.1789, val_acc=0.5242\n",
            "Epoch 18: loss=2.1243, acc=0.9052, val_loss=4.5689, val_acc=0.4571\n",
            "Epoch 19: loss=2.1388, acc=0.9154, val_loss=4.5833, val_acc=0.5066\n",
            "Epoch 20: loss=1.9456, acc=0.9294, val_loss=3.8989, val_acc=0.4978\n",
            "Epoch 21: loss=1.9759, acc=0.9179, val_loss=4.9709, val_acc=0.3879\n",
            "Epoch 22: loss=2.1963, acc=0.9060, val_loss=4.4239, val_acc=0.4868\n",
            "Epoch 23: loss=2.0443, acc=0.9335, val_loss=3.8989, val_acc=0.5308\n",
            "Epoch 24: loss=1.7880, acc=0.9481, val_loss=3.4736, val_acc=0.5363\n",
            "Epoch 25: loss=1.7182, acc=0.9426, val_loss=4.0614, val_acc=0.4824\n",
            "Epoch 26: loss=2.0360, acc=0.9085, val_loss=4.1258, val_acc=0.5176\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.01_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 3.6098\n",
            "Accuracy: 0.5415\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 9.4184\n",
            "Accuracy: 0.2056\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 3.6846\n",
            "Accuracy: 0.5229\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–‡â–…â–„â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–†â–‡â–†â–„â–…â–‡â–ˆâ–‡â–†â–‡â–‡â–…â–‡â–ˆâ–ˆâ–‡â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–ˆâ–ƒâ–„â–â–‚â–â–â–â–â–â–â–ƒâ–†â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–â–‚â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.90852\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.03603\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.51758\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 4.12582\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.20564\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 9.41842\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.54154\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 3.60984\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.52291\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 3.68461\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.01_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/un7m6c34\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_232928-un7m6c34/logs\u001b[0m\n",
            "\n",
            "Deney 20/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 21/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.001_aug_True\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233010-932poj8w\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/932poj8w\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.1028 - loss: 2.7824 - val_accuracy: 0.1000 - val_loss: 2.7342\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.0988 - loss: 2.6079 - val_accuracy: 0.1022 - val_loss: 6.0404\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 0.1105 - loss: 2.5857 - val_accuracy: 0.1066 - val_loss: 5.1283\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.1057 - loss: 2.5344 - val_accuracy: 0.1132 - val_loss: 21.7329\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0988 - loss: 2.5393 - val_accuracy: 0.1000 - val_loss: 74.6648\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1070 - loss: 2.5672 - val_accuracy: 0.1231 - val_loss: 86.8292\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.0963 - loss: 2.5583 - val_accuracy: 0.0934 - val_loss: 229.1012\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1009 - loss: 2.5357 - val_accuracy: 0.1088 - val_loss: 261.8177\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1013 - loss: 2.5807 - val_accuracy: 0.1505 - val_loss: 307.7889\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1004 - loss: 2.5801 - val_accuracy: 0.1154 - val_loss: 645.6140\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.1063 - loss: 2.5281 - val_accuracy: 0.1791 - val_loss: 1102.0299\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.0862 - loss: 2.5519 - val_accuracy: 0.1198 - val_loss: 1912.3224\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1107 - loss: 2.5175 - val_accuracy: 0.1956 - val_loss: 1666.0480\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 252ms/step - accuracy: 0.1002 - loss: 2.5594 - val_accuracy: 0.1176 - val_loss: 2135.8584\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1126 - loss: 2.5811 - val_accuracy: 0.1011 - val_loss: 3361.1121\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.0960 - loss: 2.5285 - val_accuracy: 0.1231 - val_loss: 3900.1025\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1114 - loss: 2.5350 - val_accuracy: 0.1000 - val_loss: 3744.9380\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1105 - loss: 2.5295 - val_accuracy: 0.1055 - val_loss: 3910.0396\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1125 - loss: 2.5578 - val_accuracy: 0.1308 - val_loss: 1748.3221\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1041 - loss: 2.5125 - val_accuracy: 0.1198 - val_loss: 2244.7849\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1020 - loss: 2.5508 - val_accuracy: 0.1330 - val_loss: 2428.2512\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1024 - loss: 2.5500 - val_accuracy: 0.1286 - val_loss: 3250.4802\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 252ms/step - accuracy: 0.1053 - loss: 2.5103 - val_accuracy: 0.1516 - val_loss: 2676.8682\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.6842, acc=0.1003, val_loss=2.7342, val_acc=0.1000\n",
            "Epoch 2: loss=2.5832, acc=0.0973, val_loss=6.0404, val_acc=0.1022\n",
            "Epoch 3: loss=2.5490, acc=0.1093, val_loss=5.1283, val_acc=0.1066\n",
            "Epoch 4: loss=2.5298, acc=0.1085, val_loss=21.7329, val_acc=0.1132\n",
            "Epoch 5: loss=2.5330, acc=0.1049, val_loss=74.6648, val_acc=0.1000\n",
            "Epoch 6: loss=2.5669, acc=0.0989, val_loss=86.8292, val_acc=0.1231\n",
            "Epoch 7: loss=2.5584, acc=0.1041, val_loss=229.1012, val_acc=0.0934\n",
            "Epoch 8: loss=2.5497, acc=0.1008, val_loss=261.8177, val_acc=0.1088\n",
            "Epoch 9: loss=2.5783, acc=0.1003, val_loss=307.7889, val_acc=0.1505\n",
            "Epoch 10: loss=2.5592, acc=0.0973, val_loss=645.6140, val_acc=0.1154\n",
            "Epoch 11: loss=2.5306, acc=0.1036, val_loss=1102.0299, val_acc=0.1791\n",
            "Epoch 12: loss=2.5459, acc=0.0904, val_loss=1912.3224, val_acc=0.1198\n",
            "Epoch 13: loss=2.5219, acc=0.1036, val_loss=1666.0480, val_acc=0.1956\n",
            "Epoch 14: loss=2.5630, acc=0.1008, val_loss=2135.8584, val_acc=0.1176\n",
            "Epoch 15: loss=2.5701, acc=0.1151, val_loss=3361.1121, val_acc=0.1011\n",
            "Epoch 16: loss=2.5352, acc=0.1008, val_loss=3900.1025, val_acc=0.1231\n",
            "Epoch 17: loss=2.5362, acc=0.1088, val_loss=3744.9380, val_acc=0.1000\n",
            "Epoch 18: loss=2.5213, acc=0.1074, val_loss=3910.0396, val_acc=0.1055\n",
            "Epoch 19: loss=2.5559, acc=0.1082, val_loss=1748.3221, val_acc=0.1308\n",
            "Epoch 20: loss=2.5184, acc=0.1027, val_loss=2244.7849, val_acc=0.1198\n",
            "Epoch 21: loss=2.5420, acc=0.1019, val_loss=2428.2512, val_acc=0.1330\n",
            "Epoch 22: loss=2.5410, acc=0.1044, val_loss=3250.4802, val_acc=0.1286\n",
            "Epoch 23: loss=2.5265, acc=0.1077, val_loss=2676.8682, val_acc=0.1516\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1673.4843\n",
            "Accuracy: 0.1862\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 1331.8009\n",
            "Accuracy: 0.1779\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1632.1995\n",
            "Accuracy: 0.1723\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–„â–ƒâ–†â–†â–…â–ƒâ–…â–„â–„â–ƒâ–…â–â–…â–„â–ˆâ–„â–†â–†â–†â–…â–„â–…â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–‚â–‚â–‚â–â–ƒâ–â–‚â–…â–ƒâ–‡â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–â–‚â–„â–ƒâ–„â–ƒâ–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–„â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–„â–…â–…â–‡â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10769\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 22\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.52646\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.15165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 2676.86816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.17795\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 1331.8009\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.18615\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1673.48425\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.17231\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1632.19946\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/932poj8w\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233010-932poj8w/logs\u001b[0m\n",
            "\n",
            "Deney 21/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 22/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.001_aug_False\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233644-ikdjw6l4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ikdjw6l4\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - accuracy: 0.3635 - loss: 2.3600 - val_accuracy: 0.1165 - val_loss: 3.8021\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6386 - loss: 1.1693 - val_accuracy: 0.1978 - val_loss: 4.2515\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7499 - loss: 0.8589 - val_accuracy: 0.1549 - val_loss: 3.9703\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8628 - loss: 0.5705 - val_accuracy: 0.1088 - val_loss: 4.2668\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9324 - loss: 0.3841 - val_accuracy: 0.1571 - val_loss: 4.1643\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.2840 - val_accuracy: 0.1780 - val_loss: 3.8247\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9924 - loss: 0.2059 - val_accuracy: 0.2626 - val_loss: 3.1257\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9902 - loss: 0.1849 - val_accuracy: 0.4154 - val_loss: 2.1770\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9845 - loss: 0.2200 - val_accuracy: 0.5110 - val_loss: 1.8167\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9964 - loss: 0.1786 - val_accuracy: 0.6099 - val_loss: 1.4535\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.1762 - val_accuracy: 0.5901 - val_loss: 1.6061\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9979 - loss: 0.1581 - val_accuracy: 0.6286 - val_loss: 1.4170\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.1470 - val_accuracy: 0.6451 - val_loss: 1.3731\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.1388 - val_accuracy: 0.6440 - val_loss: 1.3957\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1310 - val_accuracy: 0.6451 - val_loss: 1.3753\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1235 - val_accuracy: 0.6538 - val_loss: 1.3302\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1163 - val_accuracy: 0.6571 - val_loss: 1.3184\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1096 - val_accuracy: 0.6626 - val_loss: 1.3122\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.1032 - val_accuracy: 0.6538 - val_loss: 1.3208\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0973 - val_accuracy: 0.6538 - val_loss: 1.3139\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0916 - val_accuracy: 0.6626 - val_loss: 1.3175\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0859 - val_accuracy: 0.6670 - val_loss: 1.3042\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0809 - val_accuracy: 0.6637 - val_loss: 1.2974\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0759 - val_accuracy: 0.6670 - val_loss: 1.2717\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0711 - val_accuracy: 0.6582 - val_loss: 1.2776\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0666 - val_accuracy: 0.6670 - val_loss: 1.2832\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 0.6725 - val_loss: 1.2817\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0582 - val_accuracy: 0.6703 - val_loss: 1.2840\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0543 - val_accuracy: 0.6736 - val_loss: 1.2851\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0508 - val_accuracy: 0.6736 - val_loss: 1.2647\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0474 - val_accuracy: 0.6626 - val_loss: 1.2992\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0447 - val_accuracy: 0.6648 - val_loss: 1.2860\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0418 - val_accuracy: 0.6670 - val_loss: 1.3186\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0392 - val_accuracy: 0.6714 - val_loss: 1.2707\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9632 - loss: 0.1679 - val_accuracy: 0.1945 - val_loss: 37.9332\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6678 - loss: 1.3644 - val_accuracy: 0.3648 - val_loss: 5.7317\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8841 - loss: 0.7219 - val_accuracy: 0.5473 - val_loss: 2.2384\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9719 - loss: 0.4798 - val_accuracy: 0.6473 - val_loss: 1.5495\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9942 - loss: 0.3904 - val_accuracy: 0.6681 - val_loss: 1.5665\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.8965, acc=0.4445, val_loss=3.8021, val_acc=0.1165\n",
            "Epoch 2: loss=1.1715, acc=0.6407, val_loss=4.2515, val_acc=0.1978\n",
            "Epoch 3: loss=0.8543, acc=0.7552, val_loss=3.9703, val_acc=0.1549\n",
            "Epoch 4: loss=0.5573, acc=0.8648, val_loss=4.2668, val_acc=0.1088\n",
            "Epoch 5: loss=0.3784, acc=0.9313, val_loss=4.1643, val_acc=0.1571\n",
            "Epoch 6: loss=0.2783, acc=0.9662, val_loss=3.8247, val_acc=0.1780\n",
            "Epoch 7: loss=0.2028, acc=0.9901, val_loss=3.1257, val_acc=0.2626\n",
            "Epoch 8: loss=0.2138, acc=0.9810, val_loss=2.1770, val_acc=0.4154\n",
            "Epoch 9: loss=0.2156, acc=0.9857, val_loss=1.8167, val_acc=0.5110\n",
            "Epoch 10: loss=0.1763, acc=0.9962, val_loss=1.4535, val_acc=0.6099\n",
            "Epoch 11: loss=0.1786, acc=0.9945, val_loss=1.6061, val_acc=0.5901\n",
            "Epoch 12: loss=0.1572, acc=0.9981, val_loss=1.4170, val_acc=0.6286\n",
            "Epoch 13: loss=0.1451, acc=0.9997, val_loss=1.3731, val_acc=0.6451\n",
            "Epoch 14: loss=0.1375, acc=0.9995, val_loss=1.3957, val_acc=0.6440\n",
            "Epoch 15: loss=0.1293, acc=1.0000, val_loss=1.3753, val_acc=0.6451\n",
            "Epoch 16: loss=0.1219, acc=1.0000, val_loss=1.3302, val_acc=0.6538\n",
            "Epoch 17: loss=0.1148, acc=1.0000, val_loss=1.3184, val_acc=0.6571\n",
            "Epoch 18: loss=0.1081, acc=1.0000, val_loss=1.3122, val_acc=0.6626\n",
            "Epoch 19: loss=0.1018, acc=1.0000, val_loss=1.3208, val_acc=0.6538\n",
            "Epoch 20: loss=0.0959, acc=1.0000, val_loss=1.3139, val_acc=0.6538\n",
            "Epoch 21: loss=0.0902, acc=1.0000, val_loss=1.3175, val_acc=0.6626\n",
            "Epoch 22: loss=0.0847, acc=1.0000, val_loss=1.3042, val_acc=0.6670\n",
            "Epoch 23: loss=0.0798, acc=1.0000, val_loss=1.2974, val_acc=0.6637\n",
            "Epoch 24: loss=0.0748, acc=1.0000, val_loss=1.2717, val_acc=0.6670\n",
            "Epoch 25: loss=0.0700, acc=1.0000, val_loss=1.2776, val_acc=0.6582\n",
            "Epoch 26: loss=0.0655, acc=1.0000, val_loss=1.2832, val_acc=0.6670\n",
            "Epoch 27: loss=0.0612, acc=1.0000, val_loss=1.2817, val_acc=0.6725\n",
            "Epoch 28: loss=0.0572, acc=1.0000, val_loss=1.2840, val_acc=0.6703\n",
            "Epoch 29: loss=0.0534, acc=1.0000, val_loss=1.2851, val_acc=0.6736\n",
            "Epoch 30: loss=0.0500, acc=1.0000, val_loss=1.2647, val_acc=0.6736\n",
            "Epoch 31: loss=0.0467, acc=1.0000, val_loss=1.2992, val_acc=0.6626\n",
            "Epoch 32: loss=0.0440, acc=1.0000, val_loss=1.2860, val_acc=0.6648\n",
            "Epoch 33: loss=0.0413, acc=1.0000, val_loss=1.3186, val_acc=0.6670\n",
            "Epoch 34: loss=0.0386, acc=1.0000, val_loss=1.2707, val_acc=0.6714\n",
            "Epoch 35: loss=0.6051, acc=0.8437, val_loss=37.9332, val_acc=0.1945\n",
            "Epoch 36: loss=1.2757, acc=0.7003, val_loss=5.7317, val_acc=0.3648\n",
            "Epoch 37: loss=0.6856, acc=0.8981, val_loss=2.2384, val_acc=0.5473\n",
            "Epoch 38: loss=0.4671, acc=0.9745, val_loss=1.5495, val_acc=0.6473\n",
            "Epoch 39: loss=0.3842, acc=0.9942, val_loss=1.5665, val_acc=0.6681\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.4225\n",
            "Accuracy: 0.6385\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.9964\n",
            "Accuracy: 0.2164\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.4670\n",
            "Accuracy: 0.6292\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–†â–ƒâ–ƒâ–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–‚â–‚â–â–‚â–‚â–ƒâ–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–„â–†â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.99423\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 38\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.38415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.66813\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.56649\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.21641\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.99635\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.63846\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.42246\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.62923\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.46704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ikdjw6l4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233644-ikdjw6l4/logs\u001b[0m\n",
            "\n",
            "Deney 22/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 23/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.0001_aug_True\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233737-ngnvjpkv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.0001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ngnvjpkv\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 309ms/step - accuracy: 0.0949 - loss: 2.6826 - val_accuracy: 0.0967 - val_loss: 2.4147\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.1025 - loss: 2.5456 - val_accuracy: 0.1231 - val_loss: 2.5361\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1076 - loss: 2.5352 - val_accuracy: 0.1352 - val_loss: 3.0591\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1020 - loss: 2.4960 - val_accuracy: 0.1308 - val_loss: 5.6265\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1027 - loss: 2.5093 - val_accuracy: 0.1077 - val_loss: 14.2225\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1059 - loss: 2.5045 - val_accuracy: 0.1022 - val_loss: 29.2010\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0983 - loss: 2.5096 - val_accuracy: 0.1099 - val_loss: 70.1470\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 257ms/step - accuracy: 0.1027 - loss: 2.5099 - val_accuracy: 0.1396 - val_loss: 84.5105\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1049 - loss: 2.5194 - val_accuracy: 0.1462 - val_loss: 137.4860\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.1081 - loss: 2.5153 - val_accuracy: 0.1473 - val_loss: 251.1443\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1010 - loss: 2.5064 - val_accuracy: 0.1615 - val_loss: 501.3895\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1114 - loss: 2.4907 - val_accuracy: 0.1275 - val_loss: 787.2243\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1131 - loss: 2.4985 - val_accuracy: 0.1495 - val_loss: 961.7494\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1094 - loss: 2.4770 - val_accuracy: 0.1088 - val_loss: 1888.8663\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.0943 - loss: 2.5181 - val_accuracy: 0.1648 - val_loss: 1634.8397\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1162 - loss: 2.4604 - val_accuracy: 0.1319 - val_loss: 2462.5605\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0982 - loss: 2.4703 - val_accuracy: 0.1571 - val_loss: 2772.6504\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0952 - loss: 2.5012 - val_accuracy: 0.1011 - val_loss: 3492.0330\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1004 - loss: 2.5077 - val_accuracy: 0.1044 - val_loss: 3755.2080\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1087 - loss: 2.5025 - val_accuracy: 0.1231 - val_loss: 2532.4805\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1124 - loss: 2.4942 - val_accuracy: 0.1440 - val_loss: 2096.1978\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1211 - loss: 2.4948 - val_accuracy: 0.1231 - val_loss: 1903.2163\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1102 - loss: 2.4544 - val_accuracy: 0.1615 - val_loss: 1472.6648\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1012 - loss: 2.4666 - val_accuracy: 0.1571 - val_loss: 2426.0908\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.1061 - loss: 2.4879 - val_accuracy: 0.1440 - val_loss: 2981.4702\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.6358, acc=0.0912, val_loss=2.4147, val_acc=0.0967\n",
            "Epoch 2: loss=2.5368, acc=0.1069, val_loss=2.5361, val_acc=0.1231\n",
            "Epoch 3: loss=2.5476, acc=0.1058, val_loss=3.0591, val_acc=0.1352\n",
            "Epoch 4: loss=2.5069, acc=0.1052, val_loss=5.6265, val_acc=0.1308\n",
            "Epoch 5: loss=2.4962, acc=0.1052, val_loss=14.2225, val_acc=0.1077\n",
            "Epoch 6: loss=2.5042, acc=0.1069, val_loss=29.2010, val_acc=0.1022\n",
            "Epoch 7: loss=2.5034, acc=0.0951, val_loss=70.1470, val_acc=0.1099\n",
            "Epoch 8: loss=2.5070, acc=0.1019, val_loss=84.5105, val_acc=0.1396\n",
            "Epoch 9: loss=2.4876, acc=0.1088, val_loss=137.4860, val_acc=0.1462\n",
            "Epoch 10: loss=2.5071, acc=0.1022, val_loss=251.1443, val_acc=0.1473\n",
            "Epoch 11: loss=2.5003, acc=0.1047, val_loss=501.3895, val_acc=0.1615\n",
            "Epoch 12: loss=2.4796, acc=0.1154, val_loss=787.2243, val_acc=0.1275\n",
            "Epoch 13: loss=2.4880, acc=0.1107, val_loss=961.7494, val_acc=0.1495\n",
            "Epoch 14: loss=2.4788, acc=0.1082, val_loss=1888.8663, val_acc=0.1088\n",
            "Epoch 15: loss=2.4950, acc=0.0970, val_loss=1634.8397, val_acc=0.1648\n",
            "Epoch 16: loss=2.4743, acc=0.1118, val_loss=2462.5605, val_acc=0.1319\n",
            "Epoch 17: loss=2.4808, acc=0.0937, val_loss=2772.6504, val_acc=0.1571\n",
            "Epoch 18: loss=2.4848, acc=0.0992, val_loss=3492.0330, val_acc=0.1011\n",
            "Epoch 19: loss=2.4913, acc=0.0995, val_loss=3755.2080, val_acc=0.1044\n",
            "Epoch 20: loss=2.4770, acc=0.1025, val_loss=2532.4805, val_acc=0.1231\n",
            "Epoch 21: loss=2.4783, acc=0.1091, val_loss=2096.1978, val_acc=0.1440\n",
            "Epoch 22: loss=2.4869, acc=0.1124, val_loss=1903.2163, val_acc=0.1231\n",
            "Epoch 23: loss=2.4507, acc=0.1047, val_loss=1472.6648, val_acc=0.1615\n",
            "Epoch 24: loss=2.4896, acc=0.1036, val_loss=2426.0908, val_acc=0.1571\n",
            "Epoch 25: loss=2.4889, acc=0.1016, val_loss=2981.4702, val_acc=0.1440\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.0001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1660.7275\n",
            "Accuracy: 0.1641\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 1043.0757\n",
            "Accuracy: 0.1308\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1671.7051\n",
            "Accuracy: 0.1494\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–†â–…â–…â–…â–†â–‚â–„â–†â–„â–…â–ˆâ–‡â–†â–ƒâ–‡â–‚â–ƒâ–ƒâ–„â–†â–‡â–…â–…â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–„â–…â–…â–‚â–‚â–‚â–…â–†â–†â–ˆâ–„â–†â–‚â–ˆâ–…â–‡â–â–‚â–„â–†â–„â–ˆâ–‡â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–…â–„â–†â–†â–ˆâ–ˆâ–†â–…â–…â–„â–†â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.48889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.14396\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 2981.47021\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.13077\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 1043.07568\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.1641\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1660.72754\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.1494\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1671.70508\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.0001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ngnvjpkv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_233737-ngnvjpkv/logs\u001b[0m\n",
            "\n",
            "Deney 23/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 24/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_relu_lr_0.0001_aug_False\n",
            "Input Size: 128\n",
            "Activation: relu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234443-eu3k2jnz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_relu_lr_0.0001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/eu3k2jnz\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.3546 - loss: 2.2396 - val_accuracy: 0.1033 - val_loss: 2.8217\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7213 - loss: 0.9133 - val_accuracy: 0.1132 - val_loss: 3.6579\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8821 - loss: 0.4769 - val_accuracy: 0.1220 - val_loss: 3.5929\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9725 - loss: 0.2439 - val_accuracy: 0.1473 - val_loss: 3.4130\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9960 - loss: 0.1400 - val_accuracy: 0.1923 - val_loss: 3.0583\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.1075 - val_accuracy: 0.2593 - val_loss: 2.5550\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9989 - loss: 0.0916 - val_accuracy: 0.3165 - val_loss: 2.3871\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0847 - val_accuracy: 0.4154 - val_loss: 2.0001\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0807 - val_accuracy: 0.4857 - val_loss: 1.7370\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0786 - val_accuracy: 0.5516 - val_loss: 1.5598\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 0.5681 - val_loss: 1.4655\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0733 - val_accuracy: 0.5791 - val_loss: 1.4079\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0728 - val_accuracy: 0.5901 - val_loss: 1.4190\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 0.5967 - val_loss: 1.4189\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0706 - val_accuracy: 0.5835 - val_loss: 1.4257\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0705 - val_accuracy: 0.5879 - val_loss: 1.4318\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0694 - val_accuracy: 0.5945 - val_loss: 1.4368\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0686 - val_accuracy: 0.6033 - val_loss: 1.4332\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0678 - val_accuracy: 0.5934 - val_loss: 1.4274\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0673 - val_accuracy: 0.6033 - val_loss: 1.4364\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0670 - val_accuracy: 0.6066 - val_loss: 1.4437\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0668 - val_accuracy: 0.5989 - val_loss: 1.4381\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0662 - val_accuracy: 0.5978 - val_loss: 1.4347\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0662 - val_accuracy: 0.6000 - val_loss: 1.4473\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0657 - val_accuracy: 0.6055 - val_loss: 1.4508\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0654 - val_accuracy: 0.6022 - val_loss: 1.4388\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0652 - val_accuracy: 0.6033 - val_loss: 1.4424\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0647 - val_accuracy: 0.6088 - val_loss: 1.4422\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 0.6132 - val_loss: 1.4427\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0644 - val_accuracy: 0.6088 - val_loss: 1.4412\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0641 - val_accuracy: 0.6022 - val_loss: 1.4686\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0639 - val_accuracy: 0.6066 - val_loss: 1.4487\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 0.6099 - val_loss: 1.4604\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0634 - val_accuracy: 0.6099 - val_loss: 1.4540\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0632 - val_accuracy: 0.6077 - val_loss: 1.4606\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0628 - val_accuracy: 0.6022 - val_loss: 1.4601\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0625 - val_accuracy: 0.6088 - val_loss: 1.4539\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 0.6110 - val_loss: 1.4632\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0621 - val_accuracy: 0.6176 - val_loss: 1.4669\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0617 - val_accuracy: 0.6088 - val_loss: 1.4620\n",
            "Epoch 41/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0615 - val_accuracy: 0.6154 - val_loss: 1.4637\n",
            "Epoch 42/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0613 - val_accuracy: 0.6143 - val_loss: 1.4632\n",
            "Epoch 43/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0610 - val_accuracy: 0.6132 - val_loss: 1.4746\n",
            "Epoch 44/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0606 - val_accuracy: 0.6165 - val_loss: 1.4725\n",
            "Epoch 45/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0604 - val_accuracy: 0.6044 - val_loss: 1.4796\n",
            "Epoch 46/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0602 - val_accuracy: 0.6132 - val_loss: 1.4764\n",
            "Epoch 47/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0599 - val_accuracy: 0.6088 - val_loss: 1.4694\n",
            "Epoch 48/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0596 - val_accuracy: 0.6077 - val_loss: 1.4736\n",
            "Epoch 49/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0594 - val_accuracy: 0.6066 - val_loss: 1.4838\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.8695, acc=0.4371, val_loss=2.8217, val_acc=0.1033\n",
            "Epoch 2: loss=0.8792, acc=0.7332, val_loss=3.6579, val_acc=0.1132\n",
            "Epoch 3: loss=0.4623, acc=0.8863, val_loss=3.5929, val_acc=0.1220\n",
            "Epoch 4: loss=0.2371, acc=0.9717, val_loss=3.4130, val_acc=0.1473\n",
            "Epoch 5: loss=0.1365, acc=0.9951, val_loss=3.0583, val_acc=0.1923\n",
            "Epoch 6: loss=0.1064, acc=0.9986, val_loss=2.5550, val_acc=0.2593\n",
            "Epoch 7: loss=0.0929, acc=0.9995, val_loss=2.3871, val_acc=0.3165\n",
            "Epoch 8: loss=0.0855, acc=0.9997, val_loss=2.0001, val_acc=0.4154\n",
            "Epoch 9: loss=0.0812, acc=0.9997, val_loss=1.7370, val_acc=0.4857\n",
            "Epoch 10: loss=0.0776, acc=1.0000, val_loss=1.5598, val_acc=0.5516\n",
            "Epoch 11: loss=0.0752, acc=1.0000, val_loss=1.4655, val_acc=0.5681\n",
            "Epoch 12: loss=0.0735, acc=1.0000, val_loss=1.4079, val_acc=0.5791\n",
            "Epoch 13: loss=0.0733, acc=0.9997, val_loss=1.4190, val_acc=0.5901\n",
            "Epoch 14: loss=0.0720, acc=1.0000, val_loss=1.4189, val_acc=0.5967\n",
            "Epoch 15: loss=0.0706, acc=1.0000, val_loss=1.4257, val_acc=0.5835\n",
            "Epoch 16: loss=0.0702, acc=1.0000, val_loss=1.4318, val_acc=0.5879\n",
            "Epoch 17: loss=0.0691, acc=1.0000, val_loss=1.4368, val_acc=0.5945\n",
            "Epoch 18: loss=0.0683, acc=1.0000, val_loss=1.4332, val_acc=0.6033\n",
            "Epoch 19: loss=0.0679, acc=1.0000, val_loss=1.4274, val_acc=0.5934\n",
            "Epoch 20: loss=0.0673, acc=1.0000, val_loss=1.4364, val_acc=0.6033\n",
            "Epoch 21: loss=0.0671, acc=1.0000, val_loss=1.4437, val_acc=0.6066\n",
            "Epoch 22: loss=0.0668, acc=1.0000, val_loss=1.4381, val_acc=0.5989\n",
            "Epoch 23: loss=0.0661, acc=1.0000, val_loss=1.4347, val_acc=0.5978\n",
            "Epoch 24: loss=0.0660, acc=1.0000, val_loss=1.4473, val_acc=0.6000\n",
            "Epoch 25: loss=0.0656, acc=1.0000, val_loss=1.4508, val_acc=0.6055\n",
            "Epoch 26: loss=0.0654, acc=1.0000, val_loss=1.4388, val_acc=0.6022\n",
            "Epoch 27: loss=0.0651, acc=1.0000, val_loss=1.4424, val_acc=0.6033\n",
            "Epoch 28: loss=0.0648, acc=1.0000, val_loss=1.4422, val_acc=0.6088\n",
            "Epoch 29: loss=0.0645, acc=1.0000, val_loss=1.4427, val_acc=0.6132\n",
            "Epoch 30: loss=0.0644, acc=1.0000, val_loss=1.4412, val_acc=0.6088\n",
            "Epoch 31: loss=0.0641, acc=1.0000, val_loss=1.4686, val_acc=0.6022\n",
            "Epoch 32: loss=0.0639, acc=1.0000, val_loss=1.4487, val_acc=0.6066\n",
            "Epoch 33: loss=0.0636, acc=1.0000, val_loss=1.4604, val_acc=0.6099\n",
            "Epoch 34: loss=0.0634, acc=1.0000, val_loss=1.4540, val_acc=0.6099\n",
            "Epoch 35: loss=0.0631, acc=1.0000, val_loss=1.4606, val_acc=0.6077\n",
            "Epoch 36: loss=0.0628, acc=1.0000, val_loss=1.4601, val_acc=0.6022\n",
            "Epoch 37: loss=0.0625, acc=1.0000, val_loss=1.4539, val_acc=0.6088\n",
            "Epoch 38: loss=0.0622, acc=1.0000, val_loss=1.4632, val_acc=0.6110\n",
            "Epoch 39: loss=0.0620, acc=1.0000, val_loss=1.4669, val_acc=0.6176\n",
            "Epoch 40: loss=0.0617, acc=1.0000, val_loss=1.4620, val_acc=0.6088\n",
            "Epoch 41: loss=0.0614, acc=1.0000, val_loss=1.4637, val_acc=0.6154\n",
            "Epoch 42: loss=0.0612, acc=1.0000, val_loss=1.4632, val_acc=0.6143\n",
            "Epoch 43: loss=0.0609, acc=1.0000, val_loss=1.4746, val_acc=0.6132\n",
            "Epoch 44: loss=0.0606, acc=1.0000, val_loss=1.4725, val_acc=0.6165\n",
            "Epoch 45: loss=0.0604, acc=1.0000, val_loss=1.4796, val_acc=0.6044\n",
            "Epoch 46: loss=0.0601, acc=1.0000, val_loss=1.4764, val_acc=0.6132\n",
            "Epoch 47: loss=0.0598, acc=1.0000, val_loss=1.4694, val_acc=0.6088\n",
            "Epoch 48: loss=0.0595, acc=1.0000, val_loss=1.4736, val_acc=0.6077\n",
            "Epoch 49: loss=0.0593, acc=1.0000, val_loss=1.4838, val_acc=0.6066\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_relu_lr_0.0001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.5591\n",
            "Accuracy: 0.5759\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.0508\n",
            "Accuracy: 0.2511\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.6027\n",
            "Accuracy: 0.5629\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–â–‚â–‚â–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–…â–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 48\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.05928\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.60659\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.48381\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.25111\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.05082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.5759\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.55911\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.56291\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.60273\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_relu_lr_0.0001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/eu3k2jnz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234443-eu3k2jnz/logs\u001b[0m\n",
            "\n",
            "Deney 24/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 25/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.01_aug_True\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234545-cml7i3ci\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.01_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/cml7i3ci\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 346ms/step - accuracy: 0.0948 - loss: 3.7944 - val_accuracy: 0.0978 - val_loss: 170.2561\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.0957 - loss: 3.8667 - val_accuracy: 0.1154 - val_loss: 125.3692\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0973 - loss: 4.2366 - val_accuracy: 0.1044 - val_loss: 710.3414\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1050 - loss: 4.1987 - val_accuracy: 0.1011 - val_loss: 963.4854\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.0997 - loss: 4.0375 - val_accuracy: 0.1022 - val_loss: 668.6282\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0990 - loss: 3.7642 - val_accuracy: 0.1000 - val_loss: 1726.0780\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1008 - loss: 3.6658 - val_accuracy: 0.1011 - val_loss: 1631.2981\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1001 - loss: 3.5886 - val_accuracy: 0.1011 - val_loss: 1058.8816\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0958 - loss: 3.4139 - val_accuracy: 0.1000 - val_loss: 1775.5792\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0976 - loss: 3.4743 - val_accuracy: 0.1000 - val_loss: 1278.7621\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0948 - loss: 3.3170 - val_accuracy: 0.1022 - val_loss: 1131.0502\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0987 - loss: 3.1526 - val_accuracy: 0.1055 - val_loss: 1758.9905\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=3.9794, acc=0.0989, val_loss=170.2561, val_acc=0.0978\n",
            "Epoch 2: loss=3.9543, acc=0.0937, val_loss=125.3692, val_acc=0.1154\n",
            "Epoch 3: loss=4.2705, acc=0.1005, val_loss=710.3414, val_acc=0.1044\n",
            "Epoch 4: loss=4.2058, acc=0.1027, val_loss=963.4854, val_acc=0.1011\n",
            "Epoch 5: loss=3.9594, acc=0.0989, val_loss=668.6282, val_acc=0.1022\n",
            "Epoch 6: loss=3.7152, acc=0.0986, val_loss=1726.0780, val_acc=0.1000\n",
            "Epoch 7: loss=3.6662, acc=0.0953, val_loss=1631.2981, val_acc=0.1011\n",
            "Epoch 8: loss=3.5483, acc=0.1022, val_loss=1058.8816, val_acc=0.1011\n",
            "Epoch 9: loss=3.4300, acc=0.1019, val_loss=1775.5792, val_acc=0.1000\n",
            "Epoch 10: loss=3.4217, acc=0.0951, val_loss=1278.7621, val_acc=0.1000\n",
            "Epoch 11: loss=3.2708, acc=0.0953, val_loss=1131.0502, val_acc=0.1022\n",
            "Epoch 12: loss=3.1566, acc=0.1016, val_loss=1758.9905, val_acc=0.1055\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.01_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 127.7096\n",
            "Accuracy: 0.1103\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 81.2438\n",
            "Accuracy: 0.1091\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 127.5587\n",
            "Accuracy: 0.1089\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–…â–â–†â–ˆâ–…â–…â–‚â–ˆâ–‡â–‚â–‚â–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–†â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–†â–†â–ˆâ–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–ˆâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–ƒâ–…â–ƒâ–ˆâ–‡â–…â–ˆâ–†â–…â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 3.15662\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.10549\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1758.99048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.10906\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 81.24377\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.11026\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 127.70964\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.10889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 127.55875\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.01_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/cml7i3ci\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234545-cml7i3ci/logs\u001b[0m\n",
            "\n",
            "Deney 25/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 26/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.01_aug_False\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234921-ix2bxvs1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.01_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ix2bxvs1\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - accuracy: 0.3130 - loss: 4.0806 - val_accuracy: 0.2780 - val_loss: 5.6127\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5346 - loss: 3.7780 - val_accuracy: 0.2418 - val_loss: 4.6432\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6284 - loss: 2.9381 - val_accuracy: 0.3220 - val_loss: 4.0936\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6826 - loss: 2.4352 - val_accuracy: 0.3110 - val_loss: 3.9113\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7491 - loss: 2.0012 - val_accuracy: 0.3879 - val_loss: 3.1567\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7872 - loss: 1.8439 - val_accuracy: 0.3846 - val_loss: 3.6467\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8190 - loss: 1.7015 - val_accuracy: 0.4604 - val_loss: 3.2778\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8470 - loss: 1.6862 - val_accuracy: 0.5066 - val_loss: 3.0780\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8911 - loss: 1.5152 - val_accuracy: 0.4956 - val_loss: 3.0086\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8756 - loss: 1.5666 - val_accuracy: 0.4956 - val_loss: 3.5717\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8843 - loss: 1.6600 - val_accuracy: 0.5451 - val_loss: 3.1249\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8973 - loss: 1.5229 - val_accuracy: 0.5440 - val_loss: 3.3930\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9078 - loss: 1.5219 - val_accuracy: 0.4462 - val_loss: 4.3290\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9040 - loss: 1.4831 - val_accuracy: 0.5440 - val_loss: 3.4547\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 1.5648 - val_accuracy: 0.5418 - val_loss: 3.2668\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9243 - loss: 1.4105 - val_accuracy: 0.3637 - val_loss: 4.9891\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9057 - loss: 1.4640 - val_accuracy: 0.5341 - val_loss: 3.6099\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 1.4641 - val_accuracy: 0.5264 - val_loss: 3.7751\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9186 - loss: 1.4427 - val_accuracy: 0.5824 - val_loss: 3.2707\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9246 - loss: 1.3842 - val_accuracy: 0.4813 - val_loss: 3.6337\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9356 - loss: 1.2980 - val_accuracy: 0.5703 - val_loss: 3.0323\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9396 - loss: 1.2166 - val_accuracy: 0.5802 - val_loss: 3.0304\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 1.3301 - val_accuracy: 0.4132 - val_loss: 4.7711\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9220 - loss: 1.4022 - val_accuracy: 0.5110 - val_loss: 3.6790\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 1.1490 - val_accuracy: 0.5670 - val_loss: 3.2533\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9461 - loss: 1.0932 - val_accuracy: 0.5231 - val_loss: 3.4672\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9375 - loss: 1.1105 - val_accuracy: 0.5000 - val_loss: 3.9589\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9411 - loss: 1.1825 - val_accuracy: 0.5418 - val_loss: 3.6060\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9440 - loss: 1.1130 - val_accuracy: 0.5000 - val_loss: 3.2530\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=4.1851, acc=0.3929, val_loss=5.6127, val_acc=0.2780\n",
            "Epoch 2: loss=3.6197, acc=0.5398, val_loss=4.6432, val_acc=0.2418\n",
            "Epoch 3: loss=2.8693, acc=0.6228, val_loss=4.0936, val_acc=0.3220\n",
            "Epoch 4: loss=2.4114, acc=0.6706, val_loss=3.9113, val_acc=0.3110\n",
            "Epoch 5: loss=2.0589, acc=0.7250, val_loss=3.1567, val_acc=0.3879\n",
            "Epoch 6: loss=1.8882, acc=0.7714, val_loss=3.6467, val_acc=0.3846\n",
            "Epoch 7: loss=1.7476, acc=0.8016, val_loss=3.2778, val_acc=0.4604\n",
            "Epoch 8: loss=1.7020, acc=0.8365, val_loss=3.0780, val_acc=0.5066\n",
            "Epoch 9: loss=1.5429, acc=0.8723, val_loss=3.0086, val_acc=0.4956\n",
            "Epoch 10: loss=1.6532, acc=0.8511, val_loss=3.5717, val_acc=0.4956\n",
            "Epoch 11: loss=1.6424, acc=0.8780, val_loss=3.1249, val_acc=0.5451\n",
            "Epoch 12: loss=1.5428, acc=0.8865, val_loss=3.3930, val_acc=0.5440\n",
            "Epoch 13: loss=1.5466, acc=0.8984, val_loss=4.3290, val_acc=0.4462\n",
            "Epoch 14: loss=1.5489, acc=0.8865, val_loss=3.4547, val_acc=0.5440\n",
            "Epoch 15: loss=1.5516, acc=0.9096, val_loss=3.2668, val_acc=0.5418\n",
            "Epoch 16: loss=1.4200, acc=0.9143, val_loss=4.9891, val_acc=0.3637\n",
            "Epoch 17: loss=1.5104, acc=0.8959, val_loss=3.6099, val_acc=0.5341\n",
            "Epoch 18: loss=1.4726, acc=0.9110, val_loss=3.7751, val_acc=0.5264\n",
            "Epoch 19: loss=1.4700, acc=0.9121, val_loss=3.2707, val_acc=0.5824\n",
            "Epoch 20: loss=1.3904, acc=0.9170, val_loss=3.6337, val_acc=0.4813\n",
            "Epoch 21: loss=1.2857, acc=0.9291, val_loss=3.0323, val_acc=0.5703\n",
            "Epoch 22: loss=1.2096, acc=0.9349, val_loss=3.0304, val_acc=0.5802\n",
            "Epoch 23: loss=1.4230, acc=0.9011, val_loss=4.7711, val_acc=0.4132\n",
            "Epoch 24: loss=1.3723, acc=0.9195, val_loss=3.6790, val_acc=0.5110\n",
            "Epoch 25: loss=1.1231, acc=0.9448, val_loss=3.2533, val_acc=0.5670\n",
            "Epoch 26: loss=1.1155, acc=0.9360, val_loss=3.4672, val_acc=0.5231\n",
            "Epoch 27: loss=1.1627, acc=0.9206, val_loss=3.9589, val_acc=0.5000\n",
            "Epoch 28: loss=1.2080, acc=0.9288, val_loss=3.6060, val_acc=0.5418\n",
            "Epoch 29: loss=1.0685, acc=0.9467, val_loss=3.2530, val_acc=0.5000\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.01_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 3.3786\n",
            "Accuracy: 0.5769\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 8.8696\n",
            "Accuracy: 0.2284\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 3.3591\n",
            "Accuracy: 0.5670\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–‡â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–‚â–â–ƒâ–‚â–„â–„â–…â–†â–†â–†â–‡â–‡â–…â–‡â–‡â–„â–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–…â–‡â–ˆâ–‡â–†â–‡â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–ˆâ–…â–„â–ƒâ–â–ƒâ–‚â–â–â–ƒâ–â–‚â–…â–‚â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–â–â–†â–ƒâ–‚â–‚â–„â–ƒâ–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.9467\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 28\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 1.06852\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 3.25296\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.22838\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 8.86957\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.57692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 3.37865\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.56701\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 3.35914\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.01_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/ix2bxvs1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_234921-ix2bxvs1/logs\u001b[0m\n",
            "\n",
            "Deney 26/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 27/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.001_aug_True\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235006-3m3ee27f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/3m3ee27f\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 319ms/step - accuracy: 0.0920 - loss: 2.6403 - val_accuracy: 0.1000 - val_loss: 3.4726\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.1069 - loss: 2.5992 - val_accuracy: 0.1505 - val_loss: 5.2143\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0921 - loss: 2.5830 - val_accuracy: 0.1099 - val_loss: 22.4257\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0898 - loss: 2.6037 - val_accuracy: 0.1022 - val_loss: 42.4595\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1093 - loss: 2.5911 - val_accuracy: 0.1198 - val_loss: 73.3670\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1147 - loss: 2.6174 - val_accuracy: 0.1121 - val_loss: 129.0474\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0945 - loss: 2.5821 - val_accuracy: 0.1165 - val_loss: 199.4797\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.0883 - loss: 2.6758 - val_accuracy: 0.1132 - val_loss: 426.1698\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1075 - loss: 2.5917 - val_accuracy: 0.1560 - val_loss: 462.6438\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0978 - loss: 2.6022 - val_accuracy: 0.1275 - val_loss: 599.3432\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1030 - loss: 2.5963 - val_accuracy: 0.1264 - val_loss: 1695.8765\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0976 - loss: 2.5963 - val_accuracy: 0.0956 - val_loss: 1751.6547\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1056 - loss: 2.6035 - val_accuracy: 0.1011 - val_loss: 1868.1140\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1064 - loss: 2.6147 - val_accuracy: 0.1198 - val_loss: 1471.4100\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0997 - loss: 2.6499 - val_accuracy: 0.1066 - val_loss: 1588.9832\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1052 - loss: 2.6679 - val_accuracy: 0.1077 - val_loss: 2584.2837\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1136 - loss: 2.6508 - val_accuracy: 0.1000 - val_loss: 5577.8892\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1130 - loss: 2.6193 - val_accuracy: 0.1429 - val_loss: 3322.6506\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0989 - loss: 2.6180 - val_accuracy: 0.1110 - val_loss: 3230.4229\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.6230, acc=0.0940, val_loss=3.4726, val_acc=0.1000\n",
            "Epoch 2: loss=2.6016, acc=0.1047, val_loss=5.2143, val_acc=0.1505\n",
            "Epoch 3: loss=2.6010, acc=0.0937, val_loss=22.4257, val_acc=0.1099\n",
            "Epoch 4: loss=2.6235, acc=0.0942, val_loss=42.4595, val_acc=0.1022\n",
            "Epoch 5: loss=2.6095, acc=0.1066, val_loss=73.3670, val_acc=0.1198\n",
            "Epoch 6: loss=2.6026, acc=0.1118, val_loss=129.0474, val_acc=0.1121\n",
            "Epoch 7: loss=2.5802, acc=0.0997, val_loss=199.4797, val_acc=0.1165\n",
            "Epoch 8: loss=2.6532, acc=0.0967, val_loss=426.1698, val_acc=0.1132\n",
            "Epoch 9: loss=2.5968, acc=0.1091, val_loss=462.6438, val_acc=0.1560\n",
            "Epoch 10: loss=2.6028, acc=0.0956, val_loss=599.3432, val_acc=0.1275\n",
            "Epoch 11: loss=2.6162, acc=0.0956, val_loss=1695.8765, val_acc=0.1264\n",
            "Epoch 12: loss=2.6123, acc=0.0992, val_loss=1751.6547, val_acc=0.0956\n",
            "Epoch 13: loss=2.6212, acc=0.1074, val_loss=1868.1140, val_acc=0.1011\n",
            "Epoch 14: loss=2.6128, acc=0.1071, val_loss=1471.4100, val_acc=0.1198\n",
            "Epoch 15: loss=2.6569, acc=0.0997, val_loss=1588.9832, val_acc=0.1066\n",
            "Epoch 16: loss=2.6527, acc=0.1047, val_loss=2584.2837, val_acc=0.1077\n",
            "Epoch 17: loss=2.6413, acc=0.1077, val_loss=5577.8892, val_acc=0.1000\n",
            "Epoch 18: loss=2.6143, acc=0.1058, val_loss=3322.6506, val_acc=0.1429\n",
            "Epoch 19: loss=2.6242, acc=0.0975, val_loss=3230.4229, val_acc=0.1110\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 459.4242\n",
            "Accuracy: 0.1431\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 299.4264\n",
            "Accuracy: 0.1402\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 452.3271\n",
            "Accuracy: 0.1427\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–…â–â–â–†â–ˆâ–ƒâ–‚â–‡â–‚â–‚â–ƒâ–†â–†â–ƒâ–…â–†â–†â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–…â–ƒâ–ƒâ–…â–„â–ƒâ–â–ˆâ–ƒâ–ƒâ–„â–„â–…â–„â–ˆâ–ˆâ–‡â–„â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–‚â–‡â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ˆâ–…â–…â–â–‚â–„â–‚â–‚â–‚â–†â–ƒ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–…â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.09753\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.62418\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.11099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 3230.42285\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.14017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 299.42642\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.14308\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 459.42416\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.14274\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 452.32706\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/3m3ee27f\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235006-3m3ee27f/logs\u001b[0m\n",
            "\n",
            "Deney 27/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 28/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.001_aug_False\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235533-pp4fbfkc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/pp4fbfkc\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - accuracy: 0.3774 - loss: 2.4047 - val_accuracy: 0.1000 - val_loss: 3.5508\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6494 - loss: 1.1477 - val_accuracy: 0.1484 - val_loss: 3.8014\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7856 - loss: 0.7698 - val_accuracy: 0.1220 - val_loss: 3.6922\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8901 - loss: 0.4706 - val_accuracy: 0.1890 - val_loss: 3.4680\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9616 - loss: 0.2970 - val_accuracy: 0.1956 - val_loss: 3.9823\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9841 - loss: 0.2091 - val_accuracy: 0.2769 - val_loss: 2.9823\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9879 - loss: 0.1781 - val_accuracy: 0.2890 - val_loss: 3.1375\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9927 - loss: 0.1719 - val_accuracy: 0.4758 - val_loss: 1.9260\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1438 - val_accuracy: 0.5824 - val_loss: 1.5416\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1327 - val_accuracy: 0.6538 - val_loss: 1.2932\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.1259 - val_accuracy: 0.6758 - val_loss: 1.2446\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1206 - val_accuracy: 0.6769 - val_loss: 1.2178\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1142 - val_accuracy: 0.6923 - val_loss: 1.2056\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.1088 - val_accuracy: 0.6846 - val_loss: 1.2367\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1027 - val_accuracy: 0.6978 - val_loss: 1.2318\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0969 - val_accuracy: 0.6967 - val_loss: 1.2279\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0916 - val_accuracy: 0.6890 - val_loss: 1.2494\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0865 - val_accuracy: 0.6967 - val_loss: 1.2320\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0815 - val_accuracy: 0.6978 - val_loss: 1.2314\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0767 - val_accuracy: 0.6923 - val_loss: 1.2316\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 0.6912 - val_loss: 1.2349\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0676 - val_accuracy: 0.6945 - val_loss: 1.2303\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0634 - val_accuracy: 0.6879 - val_loss: 1.2148\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0594 - val_accuracy: 0.6846 - val_loss: 1.2249\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0556 - val_accuracy: 0.6879 - val_loss: 1.2105\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.9198, acc=0.4387, val_loss=3.5508, val_acc=0.1000\n",
            "Epoch 2: loss=1.1293, acc=0.6544, val_loss=3.8014, val_acc=0.1484\n",
            "Epoch 3: loss=0.7661, acc=0.7843, val_loss=3.6922, val_acc=0.1220\n",
            "Epoch 4: loss=0.4680, acc=0.8929, val_loss=3.4680, val_acc=0.1890\n",
            "Epoch 5: loss=0.2823, acc=0.9629, val_loss=3.9823, val_acc=0.1956\n",
            "Epoch 6: loss=0.2103, acc=0.9835, val_loss=2.9823, val_acc=0.2769\n",
            "Epoch 7: loss=0.1810, acc=0.9879, val_loss=3.1375, val_acc=0.2890\n",
            "Epoch 8: loss=0.1701, acc=0.9934, val_loss=1.9260, val_acc=0.4758\n",
            "Epoch 9: loss=0.1414, acc=1.0000, val_loss=1.5416, val_acc=0.5824\n",
            "Epoch 10: loss=0.1312, acc=1.0000, val_loss=1.2932, val_acc=0.6538\n",
            "Epoch 11: loss=0.1249, acc=0.9997, val_loss=1.2446, val_acc=0.6758\n",
            "Epoch 12: loss=0.1191, acc=1.0000, val_loss=1.2178, val_acc=0.6769\n",
            "Epoch 13: loss=0.1126, acc=1.0000, val_loss=1.2056, val_acc=0.6923\n",
            "Epoch 14: loss=0.1073, acc=0.9997, val_loss=1.2367, val_acc=0.6846\n",
            "Epoch 15: loss=0.1013, acc=1.0000, val_loss=1.2318, val_acc=0.6978\n",
            "Epoch 16: loss=0.0957, acc=1.0000, val_loss=1.2279, val_acc=0.6967\n",
            "Epoch 17: loss=0.0904, acc=1.0000, val_loss=1.2494, val_acc=0.6890\n",
            "Epoch 18: loss=0.0853, acc=1.0000, val_loss=1.2320, val_acc=0.6967\n",
            "Epoch 19: loss=0.0804, acc=1.0000, val_loss=1.2314, val_acc=0.6978\n",
            "Epoch 20: loss=0.0756, acc=1.0000, val_loss=1.2316, val_acc=0.6923\n",
            "Epoch 21: loss=0.0710, acc=1.0000, val_loss=1.2349, val_acc=0.6912\n",
            "Epoch 22: loss=0.0666, acc=1.0000, val_loss=1.2303, val_acc=0.6945\n",
            "Epoch 23: loss=0.0625, acc=1.0000, val_loss=1.2148, val_acc=0.6879\n",
            "Epoch 24: loss=0.0585, acc=1.0000, val_loss=1.2249, val_acc=0.6846\n",
            "Epoch 25: loss=0.0547, acc=1.0000, val_loss=1.2105, val_acc=0.6879\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.2685\n",
            "Accuracy: 0.6626\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.5837\n",
            "Accuracy: 0.2022\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.3120\n",
            "Accuracy: 0.6545\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–‚â–â–‚â–‚â–ƒâ–ƒâ–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–‡â–ˆâ–‡â–‡â–ˆâ–…â–†â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.05473\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.68791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.21046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.20222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.58373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.66256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.26846\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.65453\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.31203\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/pp4fbfkc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235533-pp4fbfkc/logs\u001b[0m\n",
            "\n",
            "Deney 28/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 29/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.0001_aug_True\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235618-yp0vl361\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.0001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/yp0vl361\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 319ms/step - accuracy: 0.1124 - loss: 2.6899 - val_accuracy: 0.1385 - val_loss: 2.3917\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0924 - loss: 2.5812 - val_accuracy: 0.1275 - val_loss: 2.4060\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.1000 - loss: 2.5546 - val_accuracy: 0.1473 - val_loss: 2.7277\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1108 - loss: 2.4655 - val_accuracy: 0.1462 - val_loss: 4.1108\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1075 - loss: 2.5201 - val_accuracy: 0.1319 - val_loss: 15.0401\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0957 - loss: 2.5220 - val_accuracy: 0.1418 - val_loss: 13.1109\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1081 - loss: 2.5222 - val_accuracy: 0.1055 - val_loss: 41.8163\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1136 - loss: 2.4568 - val_accuracy: 0.1033 - val_loss: 151.5309\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1037 - loss: 2.5322 - val_accuracy: 0.1582 - val_loss: 179.2810\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0981 - loss: 2.4975 - val_accuracy: 0.1484 - val_loss: 387.8190\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 246ms/step - accuracy: 0.1133 - loss: 2.4953 - val_accuracy: 0.1286 - val_loss: 579.6686\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.0967 - loss: 2.4833 - val_accuracy: 0.1725 - val_loss: 753.3301\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 252ms/step - accuracy: 0.0962 - loss: 2.5286 - val_accuracy: 0.1121 - val_loss: 1967.5316\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1097 - loss: 2.4733 - val_accuracy: 0.1615 - val_loss: 1610.8102\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1096 - loss: 2.4714 - val_accuracy: 0.1813 - val_loss: 1711.9968\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1152 - loss: 2.4591 - val_accuracy: 0.1747 - val_loss: 1927.3479\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1010 - loss: 2.4775 - val_accuracy: 0.1484 - val_loss: 2830.4468\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1155 - loss: 2.4793 - val_accuracy: 0.1648 - val_loss: 3088.7065\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1066 - loss: 2.4727 - val_accuracy: 0.1747 - val_loss: 2042.1471\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1079 - loss: 2.4999 - val_accuracy: 0.1560 - val_loss: 2142.6438\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1025 - loss: 2.4805 - val_accuracy: 0.1242 - val_loss: 3670.5300\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1048 - loss: 2.5066 - val_accuracy: 0.1231 - val_loss: 3021.0144\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1152 - loss: 2.4752 - val_accuracy: 0.1451 - val_loss: 1736.7356\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.0992 - loss: 2.4917 - val_accuracy: 0.1407 - val_loss: 1802.7393\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1081 - loss: 2.4474 - val_accuracy: 0.1769 - val_loss: 1430.3495\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.6626, acc=0.1052, val_loss=2.3917, val_acc=0.1385\n",
            "Epoch 2: loss=2.5761, acc=0.1003, val_loss=2.4060, val_acc=0.1275\n",
            "Epoch 3: loss=2.5618, acc=0.1044, val_loss=2.7277, val_acc=0.1473\n",
            "Epoch 4: loss=2.4833, acc=0.1071, val_loss=4.1108, val_acc=0.1462\n",
            "Epoch 5: loss=2.5058, acc=0.1069, val_loss=15.0401, val_acc=0.1319\n",
            "Epoch 6: loss=2.5266, acc=0.0984, val_loss=13.1109, val_acc=0.1418\n",
            "Epoch 7: loss=2.5155, acc=0.1038, val_loss=41.8163, val_acc=0.1055\n",
            "Epoch 8: loss=2.5051, acc=0.1077, val_loss=151.5309, val_acc=0.1033\n",
            "Epoch 9: loss=2.5175, acc=0.1030, val_loss=179.2810, val_acc=0.1582\n",
            "Epoch 10: loss=2.4999, acc=0.1038, val_loss=387.8190, val_acc=0.1484\n",
            "Epoch 11: loss=2.5022, acc=0.1129, val_loss=579.6686, val_acc=0.1286\n",
            "Epoch 12: loss=2.4829, acc=0.1003, val_loss=753.3301, val_acc=0.1725\n",
            "Epoch 13: loss=2.5147, acc=0.0984, val_loss=1967.5316, val_acc=0.1121\n",
            "Epoch 14: loss=2.4858, acc=0.1049, val_loss=1610.8102, val_acc=0.1615\n",
            "Epoch 15: loss=2.4860, acc=0.1088, val_loss=1711.9968, val_acc=0.1813\n",
            "Epoch 16: loss=2.4913, acc=0.1093, val_loss=1927.3479, val_acc=0.1747\n",
            "Epoch 17: loss=2.4862, acc=0.0989, val_loss=2830.4468, val_acc=0.1484\n",
            "Epoch 18: loss=2.4816, acc=0.1107, val_loss=3088.7065, val_acc=0.1648\n",
            "Epoch 19: loss=2.4940, acc=0.1154, val_loss=2042.1471, val_acc=0.1747\n",
            "Epoch 20: loss=2.4682, acc=0.1082, val_loss=2142.6438, val_acc=0.1560\n",
            "Epoch 21: loss=2.4957, acc=0.1066, val_loss=3670.5300, val_acc=0.1242\n",
            "Epoch 22: loss=2.4994, acc=0.1019, val_loss=3021.0144, val_acc=0.1231\n",
            "Epoch 23: loss=2.4807, acc=0.1091, val_loss=1736.7356, val_acc=0.1451\n",
            "Epoch 24: loss=2.4663, acc=0.1030, val_loss=1802.7393, val_acc=0.1407\n",
            "Epoch 25: loss=2.4522, acc=0.1071, val_loss=1430.3495, val_acc=0.1769\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.0001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1714.1300\n",
            "Accuracy: 0.1815\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 1108.0610\n",
            "Accuracy: 0.1733\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1711.1785\n",
            "Accuracy: 0.1658\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–„â–‚â–ƒâ–…â–…â–â–ƒâ–…â–ƒâ–ƒâ–‡â–‚â–â–„â–…â–†â–â–†â–ˆâ–…â–„â–‚â–…â–ƒâ–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–„â–ƒâ–…â–…â–„â–„â–â–â–†â–…â–ƒâ–‡â–‚â–†â–ˆâ–‡â–…â–‡â–‡â–†â–ƒâ–ƒâ–…â–„â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–…â–„â–„â–…â–†â–‡â–…â–…â–ˆâ–‡â–„â–„â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10714\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.45221\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.17692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1430.34949\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.17333\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 1108.06104\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.18154\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1714.13\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.16581\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1711.17847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.0001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/yp0vl361\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241222_235618-yp0vl361/logs\u001b[0m\n",
            "\n",
            "Deney 29/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 30/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.0001_aug_False\n",
            "Input Size: 128\n",
            "Activation: prelu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000324-kqpoijrd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_prelu_lr_0.0001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/kqpoijrd\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu (\u001b[94mPReLU\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚         \u001b[32m524,288\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_1 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚         \u001b[32m262,144\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_2 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚         \u001b[32m131,072\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p_re_lu_3 (\u001b[94mPReLU\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m9,404,362\u001b[0m (35.87 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m9,403,402\u001b[0m (35.87 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - accuracy: 0.3474 - loss: 2.2242 - val_accuracy: 0.1000 - val_loss: 3.0534\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7197 - loss: 0.8869 - val_accuracy: 0.1022 - val_loss: 4.5871\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8808 - loss: 0.4969 - val_accuracy: 0.1516 - val_loss: 5.5286\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9630 - loss: 0.2429 - val_accuracy: 0.1648 - val_loss: 5.4379\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9870 - loss: 0.1491 - val_accuracy: 0.1484 - val_loss: 5.0622\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 0.1057 - val_accuracy: 0.1637 - val_loss: 4.3714\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0942 - val_accuracy: 0.2440 - val_loss: 3.3812\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0826 - val_accuracy: 0.3648 - val_loss: 2.5166\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0774 - val_accuracy: 0.4747 - val_loss: 2.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0755 - val_accuracy: 0.5341 - val_loss: 1.6725\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0750 - val_accuracy: 0.5769 - val_loss: 1.4618\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0739 - val_accuracy: 0.5934 - val_loss: 1.4463\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9995 - loss: 0.0750 - val_accuracy: 0.6099 - val_loss: 1.3843\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0714 - val_accuracy: 0.6220 - val_loss: 1.3263\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 0.6231 - val_loss: 1.3331\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0690 - val_accuracy: 0.6275 - val_loss: 1.3454\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0686 - val_accuracy: 0.6264 - val_loss: 1.3487\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0681 - val_accuracy: 0.6275 - val_loss: 1.3464\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0675 - val_accuracy: 0.6209 - val_loss: 1.3445\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0670 - val_accuracy: 0.6198 - val_loss: 1.3532\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0667 - val_accuracy: 0.6297 - val_loss: 1.3486\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0664 - val_accuracy: 0.6209 - val_loss: 1.3602\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 0.6253 - val_loss: 1.3651\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0656 - val_accuracy: 0.6286 - val_loss: 1.3559\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0654 - val_accuracy: 0.6352 - val_loss: 1.3715\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0652 - val_accuracy: 0.6319 - val_loss: 1.3556\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 0.6253 - val_loss: 1.3901\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0647 - val_accuracy: 0.6308 - val_loss: 1.3612\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 0.6330 - val_loss: 1.3730\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0642 - val_accuracy: 0.6352 - val_loss: 1.3625\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0639 - val_accuracy: 0.6286 - val_loss: 1.3735\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.6297 - val_loss: 1.3686\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0633 - val_accuracy: 0.6330 - val_loss: 1.3729\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0633 - val_accuracy: 0.6363 - val_loss: 1.3769\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0630 - val_accuracy: 0.6275 - val_loss: 1.3923\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0627 - val_accuracy: 0.6330 - val_loss: 1.3944\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0625 - val_accuracy: 0.6341 - val_loss: 1.3933\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 0.6363 - val_loss: 1.3939\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0620 - val_accuracy: 0.6253 - val_loss: 1.3916\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0617 - val_accuracy: 0.6308 - val_loss: 1.3915\n",
            "Epoch 41/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0614 - val_accuracy: 0.6352 - val_loss: 1.3927\n",
            "Epoch 42/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0611 - val_accuracy: 0.6319 - val_loss: 1.3975\n",
            "Epoch 43/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0609 - val_accuracy: 0.6363 - val_loss: 1.3923\n",
            "Epoch 44/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0606 - val_accuracy: 0.6352 - val_loss: 1.3970\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.8311, acc=0.4382, val_loss=3.0534, val_acc=0.1000\n",
            "Epoch 2: loss=0.8628, acc=0.7365, val_loss=4.5871, val_acc=0.1022\n",
            "Epoch 3: loss=0.4819, acc=0.8816, val_loss=5.5286, val_acc=0.1516\n",
            "Epoch 4: loss=0.2334, acc=0.9648, val_loss=5.4379, val_acc=0.1648\n",
            "Epoch 5: loss=0.1471, acc=0.9909, val_loss=5.0622, val_acc=0.1484\n",
            "Epoch 6: loss=0.1054, acc=0.9975, val_loss=4.3714, val_acc=0.1637\n",
            "Epoch 7: loss=0.0918, acc=0.9997, val_loss=3.3812, val_acc=0.2440\n",
            "Epoch 8: loss=0.0819, acc=1.0000, val_loss=2.5166, val_acc=0.3648\n",
            "Epoch 9: loss=0.0776, acc=1.0000, val_loss=2.0010, val_acc=0.4747\n",
            "Epoch 10: loss=0.0753, acc=1.0000, val_loss=1.6725, val_acc=0.5341\n",
            "Epoch 11: loss=0.0744, acc=1.0000, val_loss=1.4618, val_acc=0.5769\n",
            "Epoch 12: loss=0.0753, acc=0.9992, val_loss=1.4463, val_acc=0.5934\n",
            "Epoch 13: loss=0.0744, acc=0.9997, val_loss=1.3843, val_acc=0.6099\n",
            "Epoch 14: loss=0.0710, acc=1.0000, val_loss=1.3263, val_acc=0.6220\n",
            "Epoch 15: loss=0.0699, acc=1.0000, val_loss=1.3331, val_acc=0.6231\n",
            "Epoch 16: loss=0.0692, acc=1.0000, val_loss=1.3454, val_acc=0.6275\n",
            "Epoch 17: loss=0.0687, acc=1.0000, val_loss=1.3487, val_acc=0.6264\n",
            "Epoch 18: loss=0.0681, acc=1.0000, val_loss=1.3464, val_acc=0.6275\n",
            "Epoch 19: loss=0.0676, acc=1.0000, val_loss=1.3445, val_acc=0.6209\n",
            "Epoch 20: loss=0.0671, acc=1.0000, val_loss=1.3532, val_acc=0.6198\n",
            "Epoch 21: loss=0.0667, acc=1.0000, val_loss=1.3486, val_acc=0.6297\n",
            "Epoch 22: loss=0.0664, acc=1.0000, val_loss=1.3602, val_acc=0.6209\n",
            "Epoch 23: loss=0.0660, acc=1.0000, val_loss=1.3651, val_acc=0.6253\n",
            "Epoch 24: loss=0.0657, acc=1.0000, val_loss=1.3559, val_acc=0.6286\n",
            "Epoch 25: loss=0.0654, acc=1.0000, val_loss=1.3715, val_acc=0.6352\n",
            "Epoch 26: loss=0.0652, acc=1.0000, val_loss=1.3556, val_acc=0.6319\n",
            "Epoch 27: loss=0.0651, acc=1.0000, val_loss=1.3901, val_acc=0.6253\n",
            "Epoch 28: loss=0.0647, acc=1.0000, val_loss=1.3612, val_acc=0.6308\n",
            "Epoch 29: loss=0.0645, acc=1.0000, val_loss=1.3730, val_acc=0.6330\n",
            "Epoch 30: loss=0.0642, acc=1.0000, val_loss=1.3625, val_acc=0.6352\n",
            "Epoch 31: loss=0.0639, acc=1.0000, val_loss=1.3735, val_acc=0.6286\n",
            "Epoch 32: loss=0.0638, acc=1.0000, val_loss=1.3686, val_acc=0.6297\n",
            "Epoch 33: loss=0.0634, acc=1.0000, val_loss=1.3729, val_acc=0.6330\n",
            "Epoch 34: loss=0.0633, acc=1.0000, val_loss=1.3769, val_acc=0.6363\n",
            "Epoch 35: loss=0.0629, acc=1.0000, val_loss=1.3923, val_acc=0.6275\n",
            "Epoch 36: loss=0.0627, acc=1.0000, val_loss=1.3944, val_acc=0.6330\n",
            "Epoch 37: loss=0.0624, acc=1.0000, val_loss=1.3933, val_acc=0.6341\n",
            "Epoch 38: loss=0.0621, acc=1.0000, val_loss=1.3939, val_acc=0.6363\n",
            "Epoch 39: loss=0.0619, acc=1.0000, val_loss=1.3916, val_acc=0.6253\n",
            "Epoch 40: loss=0.0617, acc=1.0000, val_loss=1.3915, val_acc=0.6308\n",
            "Epoch 41: loss=0.0614, acc=1.0000, val_loss=1.3927, val_acc=0.6352\n",
            "Epoch 42: loss=0.0611, acc=1.0000, val_loss=1.3975, val_acc=0.6319\n",
            "Epoch 43: loss=0.0609, acc=1.0000, val_loss=1.3923, val_acc=0.6363\n",
            "Epoch 44: loss=0.0606, acc=1.0000, val_loss=1.3970, val_acc=0.6352\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_prelu_lr_0.0001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.5535\n",
            "Accuracy: 0.5928\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.9918\n",
            "Accuracy: 0.1933\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.6103\n",
            "Accuracy: 0.5735\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–„â–†â–ˆâ–ˆâ–‡â–†â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 43\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.06062\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.63516\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.39704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.19333\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.99185\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.59282\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.55345\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.5735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.61033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_prelu_lr_0.0001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/kqpoijrd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000324-kqpoijrd/logs\u001b[0m\n",
            "\n",
            "Deney 30/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 31/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.01_aug_True\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000426-1dte8pij\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.01_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/1dte8pij\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 341ms/step - accuracy: 0.1022 - loss: 3.6778 - val_accuracy: 0.1000 - val_loss: 143.9464\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 264ms/step - accuracy: 0.1013 - loss: 3.9134 - val_accuracy: 0.1275 - val_loss: 454.4317\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.0921 - loss: 4.1099 - val_accuracy: 0.1099 - val_loss: 379.7530\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 258ms/step - accuracy: 0.1143 - loss: 3.8066 - val_accuracy: 0.1330 - val_loss: 739.7221\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 253ms/step - accuracy: 0.1077 - loss: 3.5895 - val_accuracy: 0.1022 - val_loss: 504.5867\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1023 - loss: 3.4736 - val_accuracy: 0.0813 - val_loss: 3368.0459\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1114 - loss: 3.5891 - val_accuracy: 0.0978 - val_loss: 1326.2300\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1117 - loss: 3.5713 - val_accuracy: 0.0967 - val_loss: 1023.2518\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0999 - loss: 3.2749 - val_accuracy: 0.1000 - val_loss: 1268.1635\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1009 - loss: 3.1280 - val_accuracy: 0.1044 - val_loss: 410.7071\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0932 - loss: 3.0895 - val_accuracy: 0.1077 - val_loss: 687.3114\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1125 - loss: 3.1180 - val_accuracy: 0.1000 - val_loss: 10269.4248\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0940 - loss: 3.1607 - val_accuracy: 0.1011 - val_loss: 689.8580\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.0984 - loss: 3.0396 - val_accuracy: 0.1033 - val_loss: 2685.4932\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=3.9361, acc=0.1096, val_loss=143.9464, val_acc=0.1000\n",
            "Epoch 2: loss=4.0094, acc=0.1016, val_loss=454.4317, val_acc=0.1275\n",
            "Epoch 3: loss=3.9602, acc=0.0953, val_loss=379.7530, val_acc=0.1099\n",
            "Epoch 4: loss=3.7872, acc=0.1104, val_loss=739.7221, val_acc=0.1330\n",
            "Epoch 5: loss=3.5344, acc=0.1052, val_loss=504.5867, val_acc=0.1022\n",
            "Epoch 6: loss=3.5353, acc=0.1060, val_loss=3368.0459, val_acc=0.0813\n",
            "Epoch 7: loss=3.6560, acc=0.1036, val_loss=1326.2300, val_acc=0.0978\n",
            "Epoch 8: loss=3.5007, acc=0.1052, val_loss=1023.2518, val_acc=0.0967\n",
            "Epoch 9: loss=3.2172, acc=0.0962, val_loss=1268.1635, val_acc=0.1000\n",
            "Epoch 10: loss=3.1358, acc=0.0973, val_loss=410.7071, val_acc=0.1044\n",
            "Epoch 11: loss=3.0943, acc=0.0945, val_loss=687.3114, val_acc=0.1077\n",
            "Epoch 12: loss=3.1212, acc=0.1093, val_loss=10269.4248, val_acc=0.1000\n",
            "Epoch 13: loss=3.1267, acc=0.1014, val_loss=689.8580, val_acc=0.1011\n",
            "Epoch 14: loss=3.0291, acc=0.1014, val_loss=2685.4932, val_acc=0.1033\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.01_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 740.7279\n",
            "Accuracy: 0.1385\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 476.0592\n",
            "Accuracy: 0.1374\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 726.5254\n",
            "Accuracy: 0.1369\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–ˆâ–„â–â–ˆâ–†â–†â–…â–†â–‚â–‚â–â–ˆâ–„â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–‡â–ˆâ–ˆâ–†â–…â–…â–…â–„â–‚â–‚â–â–‚â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–„â–‡â–…â–ˆâ–„â–â–ƒâ–ƒâ–„â–„â–…â–„â–„â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–ƒâ–‚â–‚â–‚â–â–â–ˆâ–â–ƒ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.10137\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 13\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 3.0291\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.1033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 2685.49316\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.13744\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 476.05923\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.13846\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 740.72791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.13692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 726.52539\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.01_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/1dte8pij\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000426-1dte8pij/logs\u001b[0m\n",
            "\n",
            "Deney 31/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 32/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.01_aug_False\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.01\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000833-31sf74o4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.01_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/31sf74o4\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.2947 - loss: 4.1318 - val_accuracy: 0.2033 - val_loss: 5.9962\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4910 - loss: 3.8352 - val_accuracy: 0.2857 - val_loss: 3.9131\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5898 - loss: 3.0180 - val_accuracy: 0.3099 - val_loss: 3.6326\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6681 - loss: 2.3898 - val_accuracy: 0.3560 - val_loss: 3.1024\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7096 - loss: 2.0464 - val_accuracy: 0.2736 - val_loss: 4.0170\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7666 - loss: 1.7965 - val_accuracy: 0.4659 - val_loss: 2.9395\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8078 - loss: 1.6839 - val_accuracy: 0.4176 - val_loss: 3.1775\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8181 - loss: 1.7707 - val_accuracy: 0.4703 - val_loss: 3.1019\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8735 - loss: 1.7104 - val_accuracy: 0.3154 - val_loss: 4.7731\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8776 - loss: 1.7937 - val_accuracy: 0.4209 - val_loss: 4.2478\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8987 - loss: 1.8590 - val_accuracy: 0.4747 - val_loss: 3.8398\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8977 - loss: 1.9582 - val_accuracy: 0.4176 - val_loss: 4.5634\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9037 - loss: 2.0107 - val_accuracy: 0.5099 - val_loss: 3.7592\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9133 - loss: 1.9479 - val_accuracy: 0.4824 - val_loss: 4.0835\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9104 - loss: 2.0729 - val_accuracy: 0.4967 - val_loss: 4.4135\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9217 - loss: 2.1287 - val_accuracy: 0.5187 - val_loss: 4.0286\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9093 - loss: 2.2004 - val_accuracy: 0.4033 - val_loss: 5.7313\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 2.1931 - val_accuracy: 0.4758 - val_loss: 4.4728\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9344 - loss: 2.0821 - val_accuracy: 0.4758 - val_loss: 4.0140\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9437 - loss: 1.9728 - val_accuracy: 0.3593 - val_loss: 5.6100\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9380 - loss: 2.0528 - val_accuracy: 0.4220 - val_loss: 4.5613\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9372 - loss: 2.0024 - val_accuracy: 0.5242 - val_loss: 3.9098\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9366 - loss: 1.9220 - val_accuracy: 0.5231 - val_loss: 4.0208\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9441 - loss: 1.9440 - val_accuracy: 0.5418 - val_loss: 3.7338\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9321 - loss: 2.0248 - val_accuracy: 0.5176 - val_loss: 3.8621\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9446 - loss: 2.0102 - val_accuracy: 0.5044 - val_loss: 4.2612\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9536 - loss: 1.8082 - val_accuracy: 0.4879 - val_loss: 4.3085\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9463 - loss: 1.7973 - val_accuracy: 0.5264 - val_loss: 4.1432\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9301 - loss: 2.0602 - val_accuracy: 0.5593 - val_loss: 3.6943\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9424 - loss: 2.0054 - val_accuracy: 0.4615 - val_loss: 4.1732\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9622 - loss: 1.7639 - val_accuracy: 0.5352 - val_loss: 3.6067\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 1.6070 - val_accuracy: 0.5396 - val_loss: 3.7961\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 1.6413 - val_accuracy: 0.5132 - val_loss: 3.8272\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9376 - loss: 1.7577 - val_accuracy: 0.4462 - val_loss: 4.8525\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9234 - loss: 1.9855 - val_accuracy: 0.3956 - val_loss: 6.1654\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9535 - loss: 1.7908 - val_accuracy: 0.2879 - val_loss: 9.6479\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9597 - loss: 1.5561 - val_accuracy: 0.5462 - val_loss: 3.4698\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9621 - loss: 1.4913 - val_accuracy: 0.5352 - val_loss: 3.6981\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 1.5298 - val_accuracy: 0.5088 - val_loss: 4.7510\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=4.2399, acc=0.3654, val_loss=5.9962, val_acc=0.2033\n",
            "Epoch 2: loss=3.6397, acc=0.5102, val_loss=3.9131, val_acc=0.2857\n",
            "Epoch 3: loss=2.9469, acc=0.5739, val_loss=3.6326, val_acc=0.3099\n",
            "Epoch 4: loss=2.3862, acc=0.6453, val_loss=3.1024, val_acc=0.3560\n",
            "Epoch 5: loss=2.0786, acc=0.6852, val_loss=4.0170, val_acc=0.2736\n",
            "Epoch 6: loss=1.8531, acc=0.7420, val_loss=2.9395, val_acc=0.4659\n",
            "Epoch 7: loss=1.7630, acc=0.7780, val_loss=3.1775, val_acc=0.4176\n",
            "Epoch 8: loss=1.8371, acc=0.8016, val_loss=3.1019, val_acc=0.4703\n",
            "Epoch 9: loss=1.7654, acc=0.8544, val_loss=4.7731, val_acc=0.3154\n",
            "Epoch 10: loss=1.8706, acc=0.8582, val_loss=4.2478, val_acc=0.4209\n",
            "Epoch 11: loss=1.8796, acc=0.8843, val_loss=3.8398, val_acc=0.4747\n",
            "Epoch 12: loss=2.0507, acc=0.8827, val_loss=4.5634, val_acc=0.4176\n",
            "Epoch 13: loss=1.9893, acc=0.9000, val_loss=3.7592, val_acc=0.5099\n",
            "Epoch 14: loss=2.0021, acc=0.9008, val_loss=4.0835, val_acc=0.4824\n",
            "Epoch 15: loss=2.1105, acc=0.9014, val_loss=4.4135, val_acc=0.4967\n",
            "Epoch 16: loss=2.1549, acc=0.9058, val_loss=4.0286, val_acc=0.5187\n",
            "Epoch 17: loss=2.2198, acc=0.8970, val_loss=5.7313, val_acc=0.4033\n",
            "Epoch 18: loss=2.1838, acc=0.9118, val_loss=4.4728, val_acc=0.4758\n",
            "Epoch 19: loss=2.0712, acc=0.9231, val_loss=4.0140, val_acc=0.4758\n",
            "Epoch 20: loss=2.0009, acc=0.9212, val_loss=5.6100, val_acc=0.3593\n",
            "Epoch 21: loss=2.0573, acc=0.9264, val_loss=4.5613, val_acc=0.4220\n",
            "Epoch 22: loss=1.9918, acc=0.9275, val_loss=3.9098, val_acc=0.5242\n",
            "Epoch 23: loss=1.9584, acc=0.9239, val_loss=4.0208, val_acc=0.5231\n",
            "Epoch 24: loss=1.9660, acc=0.9275, val_loss=3.7338, val_acc=0.5418\n",
            "Epoch 25: loss=2.0764, acc=0.9170, val_loss=3.8621, val_acc=0.5176\n",
            "Epoch 26: loss=1.9753, acc=0.9363, val_loss=4.2612, val_acc=0.5044\n",
            "Epoch 27: loss=1.7984, acc=0.9418, val_loss=4.3085, val_acc=0.4879\n",
            "Epoch 28: loss=1.8909, acc=0.9203, val_loss=4.1432, val_acc=0.5264\n",
            "Epoch 29: loss=2.1150, acc=0.9126, val_loss=3.6943, val_acc=0.5593\n",
            "Epoch 30: loss=1.9757, acc=0.9335, val_loss=4.1732, val_acc=0.4615\n",
            "Epoch 31: loss=1.7308, acc=0.9500, val_loss=3.6067, val_acc=0.5352\n",
            "Epoch 32: loss=1.6210, acc=0.9467, val_loss=3.7961, val_acc=0.5396\n",
            "Epoch 33: loss=1.6656, acc=0.9379, val_loss=3.8272, val_acc=0.5132\n",
            "Epoch 34: loss=1.8416, acc=0.9247, val_loss=4.8525, val_acc=0.4462\n",
            "Epoch 35: loss=1.9862, acc=0.9220, val_loss=6.1654, val_acc=0.3956\n",
            "Epoch 36: loss=1.7257, acc=0.9511, val_loss=9.6479, val_acc=0.2879\n",
            "Epoch 37: loss=1.5445, acc=0.9552, val_loss=3.4698, val_acc=0.5462\n",
            "Epoch 38: loss=1.5090, acc=0.9486, val_loss=3.6981, val_acc=0.5352\n",
            "Epoch 39: loss=1.6077, acc=0.9415, val_loss=4.7510, val_acc=0.5088\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.01_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 3.7503\n",
            "Accuracy: 0.5431\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 7.3660\n",
            "Accuracy: 0.1991\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 3.8108\n",
            "Accuracy: 0.5289\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–†â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–ƒâ–ƒâ–„â–‚â–†â–…â–†â–ƒâ–…â–†â–…â–‡â–†â–‡â–‡â–…â–†â–†â–„â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–ˆâ–ˆâ–‡â–†â–…â–ƒâ–ˆâ–ˆâ–‡\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–„â–‚â–‚â–â–‚â–â–â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ˆâ–‚â–‚â–ƒ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.94148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 38\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 1.60769\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.50879\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 4.75097\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.19915\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 7.36599\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.54308\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 3.75031\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.52889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 3.8108\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.01_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/31sf74o4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000833-31sf74o4/logs\u001b[0m\n",
            "\n",
            "Deney 32/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 33/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.001_aug_True\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000925-06cwe8nt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/06cwe8nt\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 310ms/step - accuracy: 0.0954 - loss: 2.8242 - val_accuracy: 0.1033 - val_loss: 7.0312\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0921 - loss: 2.6107 - val_accuracy: 0.1011 - val_loss: 11.7945\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.1010 - loss: 2.6052 - val_accuracy: 0.1088 - val_loss: 9.1685\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.1131 - loss: 2.6017 - val_accuracy: 0.1396 - val_loss: 22.7377\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 255ms/step - accuracy: 0.1063 - loss: 2.5344 - val_accuracy: 0.1527 - val_loss: 11.6078\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 251ms/step - accuracy: 0.1078 - loss: 2.6008 - val_accuracy: 0.1187 - val_loss: 78.5908\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1010 - loss: 2.6070 - val_accuracy: 0.1527 - val_loss: 91.0257\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1022 - loss: 2.5553 - val_accuracy: 0.1110 - val_loss: 587.6940\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1086 - loss: 2.5925 - val_accuracy: 0.1385 - val_loss: 267.7541\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1071 - loss: 2.6078 - val_accuracy: 0.1099 - val_loss: 883.2236\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 246ms/step - accuracy: 0.0964 - loss: 2.6545 - val_accuracy: 0.1220 - val_loss: 631.8831\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0981 - loss: 2.5920 - val_accuracy: 0.0912 - val_loss: 544.7131\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1105 - loss: 2.5900 - val_accuracy: 0.1231 - val_loss: 406.2771\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0936 - loss: 2.5578 - val_accuracy: 0.1099 - val_loss: 418.1779\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1075 - loss: 2.5537 - val_accuracy: 0.1209 - val_loss: 1049.1257\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.7243, acc=0.0962, val_loss=7.0312, val_acc=0.1033\n",
            "Epoch 2: loss=2.5866, acc=0.0978, val_loss=11.7945, val_acc=0.1011\n",
            "Epoch 3: loss=2.5860, acc=0.0964, val_loss=9.1685, val_acc=0.1088\n",
            "Epoch 4: loss=2.6027, acc=0.1126, val_loss=22.7377, val_acc=0.1396\n",
            "Epoch 5: loss=2.5794, acc=0.1041, val_loss=11.6078, val_acc=0.1527\n",
            "Epoch 6: loss=2.6060, acc=0.1033, val_loss=78.5908, val_acc=0.1187\n",
            "Epoch 7: loss=2.6014, acc=0.0918, val_loss=91.0257, val_acc=0.1527\n",
            "Epoch 8: loss=2.5685, acc=0.1071, val_loss=587.6940, val_acc=0.1110\n",
            "Epoch 9: loss=2.6091, acc=0.1052, val_loss=267.7541, val_acc=0.1385\n",
            "Epoch 10: loss=2.6290, acc=0.1019, val_loss=883.2236, val_acc=0.1099\n",
            "Epoch 11: loss=2.6473, acc=0.0898, val_loss=631.8831, val_acc=0.1220\n",
            "Epoch 12: loss=2.5903, acc=0.0984, val_loss=544.7131, val_acc=0.0912\n",
            "Epoch 13: loss=2.5965, acc=0.1041, val_loss=406.2771, val_acc=0.1231\n",
            "Epoch 14: loss=2.5709, acc=0.0967, val_loss=418.1779, val_acc=0.1099\n",
            "Epoch 15: loss=2.5488, acc=0.1033, val_loss=1049.1257, val_acc=0.1209\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 11.4993\n",
            "Accuracy: 0.1697\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 24.3192\n",
            "Accuracy: 0.0897\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 9.7842\n",
            "Accuracy: 0.1728\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–ƒâ–ƒâ–ƒâ–ˆâ–…â–…â–‚â–†â–†â–…â–â–„â–…â–ƒâ–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–†â–‡â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–‚â–‚â–ƒâ–‡â–ˆâ–„â–ˆâ–ƒâ–†â–ƒâ–„â–â–…â–ƒâ–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–‚â–…â–ƒâ–‡â–…â–…â–„â–„â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.1033\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.54876\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.12088\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1049.12573\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.08974\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 24.31915\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.16974\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 11.49934\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.17282\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 9.78417\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/06cwe8nt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_000925-06cwe8nt/logs\u001b[0m\n",
            "\n",
            "Deney 33/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 34/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.001_aug_False\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001346-mmcwuusk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/mmcwuusk\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.3582 - loss: 2.5087 - val_accuracy: 0.1549 - val_loss: 2.4207\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5868 - loss: 1.3409 - val_accuracy: 0.1198 - val_loss: 2.6952\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7152 - loss: 0.9676 - val_accuracy: 0.2582 - val_loss: 2.5727\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8021 - loss: 0.7241 - val_accuracy: 0.2648 - val_loss: 2.7087\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9212 - loss: 0.4107 - val_accuracy: 0.2956 - val_loss: 2.4157\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9755 - loss: 0.2602 - val_accuracy: 0.3407 - val_loss: 2.1455\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9864 - loss: 0.2046 - val_accuracy: 0.4670 - val_loss: 1.7947\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9967 - loss: 0.1649 - val_accuracy: 0.4923 - val_loss: 1.6850\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9979 - loss: 0.1547 - val_accuracy: 0.5495 - val_loss: 1.5488\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9990 - loss: 0.1370 - val_accuracy: 0.5890 - val_loss: 1.4568\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1260 - val_accuracy: 0.6187 - val_loss: 1.4006\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1184 - val_accuracy: 0.6275 - val_loss: 1.3717\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1109 - val_accuracy: 0.6330 - val_loss: 1.3537\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1045 - val_accuracy: 0.6374 - val_loss: 1.3860\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0985 - val_accuracy: 0.6495 - val_loss: 1.3246\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0925 - val_accuracy: 0.6407 - val_loss: 1.3624\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0871 - val_accuracy: 0.6505 - val_loss: 1.3906\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0818 - val_accuracy: 0.6538 - val_loss: 1.3396\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0767 - val_accuracy: 0.6462 - val_loss: 1.3709\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0718 - val_accuracy: 0.6495 - val_loss: 1.3506\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.1211 - val_accuracy: 0.2516 - val_loss: 10.5689\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7704 - loss: 0.8432 - val_accuracy: 0.3187 - val_loss: 6.0469\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9422 - loss: 0.4687 - val_accuracy: 0.4934 - val_loss: 2.5592\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.3271 - val_accuracy: 0.6077 - val_loss: 1.7298\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.2693 - val_accuracy: 0.6110 - val_loss: 1.6806\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.2443 - val_accuracy: 0.5868 - val_loss: 1.5582\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.2299 - val_accuracy: 0.6176 - val_loss: 1.6472\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.2081 - val_accuracy: 0.6418 - val_loss: 1.4242\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.9835, acc=0.4316, val_loss=2.4207, val_acc=0.1549\n",
            "Epoch 2: loss=1.2848, acc=0.6074, val_loss=2.6952, val_acc=0.1198\n",
            "Epoch 3: loss=0.9600, acc=0.7181, val_loss=2.5727, val_acc=0.2582\n",
            "Epoch 4: loss=0.6807, acc=0.8159, val_loss=2.7087, val_acc=0.2648\n",
            "Epoch 5: loss=0.3963, acc=0.9217, val_loss=2.4157, val_acc=0.2956\n",
            "Epoch 6: loss=0.2532, acc=0.9755, val_loss=2.1455, val_acc=0.3407\n",
            "Epoch 7: loss=0.2041, acc=0.9876, val_loss=1.7947, val_acc=0.4670\n",
            "Epoch 8: loss=0.1638, acc=0.9967, val_loss=1.6850, val_acc=0.4923\n",
            "Epoch 9: loss=0.1527, acc=0.9975, val_loss=1.5488, val_acc=0.5495\n",
            "Epoch 10: loss=0.1344, acc=0.9989, val_loss=1.4568, val_acc=0.5890\n",
            "Epoch 11: loss=0.1244, acc=1.0000, val_loss=1.4006, val_acc=0.6187\n",
            "Epoch 12: loss=0.1167, acc=1.0000, val_loss=1.3717, val_acc=0.6275\n",
            "Epoch 13: loss=0.1094, acc=1.0000, val_loss=1.3537, val_acc=0.6330\n",
            "Epoch 14: loss=0.1032, acc=1.0000, val_loss=1.3860, val_acc=0.6374\n",
            "Epoch 15: loss=0.0971, acc=1.0000, val_loss=1.3246, val_acc=0.6495\n",
            "Epoch 16: loss=0.0911, acc=1.0000, val_loss=1.3624, val_acc=0.6407\n",
            "Epoch 17: loss=0.0859, acc=1.0000, val_loss=1.3906, val_acc=0.6505\n",
            "Epoch 18: loss=0.0805, acc=1.0000, val_loss=1.3396, val_acc=0.6538\n",
            "Epoch 19: loss=0.0755, acc=1.0000, val_loss=1.3709, val_acc=0.6462\n",
            "Epoch 20: loss=0.0706, acc=1.0000, val_loss=1.3506, val_acc=0.6495\n",
            "Epoch 21: loss=0.2847, acc=0.9374, val_loss=10.5689, val_acc=0.2516\n",
            "Epoch 22: loss=0.9106, acc=0.7640, val_loss=6.0469, val_acc=0.3187\n",
            "Epoch 23: loss=0.4505, acc=0.9464, val_loss=2.5592, val_acc=0.4934\n",
            "Epoch 24: loss=0.3168, acc=0.9885, val_loss=1.7298, val_acc=0.6077\n",
            "Epoch 25: loss=0.2633, acc=0.9986, val_loss=1.6806, val_acc=0.6110\n",
            "Epoch 26: loss=0.2429, acc=0.9995, val_loss=1.5582, val_acc=0.5868\n",
            "Epoch 27: loss=0.2234, acc=0.9995, val_loss=1.6472, val_acc=0.6176\n",
            "Epoch 28: loss=0.2059, acc=0.9995, val_loss=1.4242, val_acc=0.6418\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.4935\n",
            "Accuracy: 0.6031\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 3.6463\n",
            "Accuracy: 0.3197\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.5425\n",
            "Accuracy: 0.5901\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–ƒâ–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–„â–‚â–‚â–‚â–‚â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–ƒâ–ƒâ–ƒâ–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–„â–†â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–…â–‚â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.99945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.20586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.64176\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.42415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.31966\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 3.64634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.60308\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.49351\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.59009\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.54253\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/mmcwuusk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001346-mmcwuusk/logs\u001b[0m\n",
            "\n",
            "Deney 34/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 35/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.0001_aug_True\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Aktif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001432-bflq4aos\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.0001_aug_True\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/bflq4aos\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 308ms/step - accuracy: 0.1054 - loss: 2.7686 - val_accuracy: 0.1000 - val_loss: 2.5484\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1085 - loss: 2.5818 - val_accuracy: 0.1033 - val_loss: 3.4134\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 260ms/step - accuracy: 0.1025 - loss: 2.5766 - val_accuracy: 0.1154 - val_loss: 3.4032\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 259ms/step - accuracy: 0.0895 - loss: 2.5311 - val_accuracy: 0.1736 - val_loss: 4.6942\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1042 - loss: 2.5356 - val_accuracy: 0.1143 - val_loss: 16.9684\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1098 - loss: 2.4964 - val_accuracy: 0.1209 - val_loss: 45.7726\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 252ms/step - accuracy: 0.1070 - loss: 2.5356 - val_accuracy: 0.1418 - val_loss: 85.2267\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0970 - loss: 2.5801 - val_accuracy: 0.1648 - val_loss: 117.2145\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.0982 - loss: 2.5131 - val_accuracy: 0.1505 - val_loss: 194.1174\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 247ms/step - accuracy: 0.1032 - loss: 2.5087 - val_accuracy: 0.1000 - val_loss: 640.0712\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.1056 - loss: 2.5053 - val_accuracy: 0.1143 - val_loss: 715.5087\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 250ms/step - accuracy: 0.1091 - loss: 2.5431 - val_accuracy: 0.1286 - val_loss: 720.9340\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 248ms/step - accuracy: 0.0982 - loss: 2.4781 - val_accuracy: 0.1286 - val_loss: 1280.2083\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 249ms/step - accuracy: 0.1118 - loss: 2.5101 - val_accuracy: 0.1451 - val_loss: 978.2520\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=2.6943, acc=0.1063, val_loss=2.5484, val_acc=0.1000\n",
            "Epoch 2: loss=2.5721, acc=0.1016, val_loss=3.4134, val_acc=0.1033\n",
            "Epoch 3: loss=2.5883, acc=0.1055, val_loss=3.4032, val_acc=0.1154\n",
            "Epoch 4: loss=2.5359, acc=0.0942, val_loss=4.6942, val_acc=0.1736\n",
            "Epoch 5: loss=2.5436, acc=0.1041, val_loss=16.9684, val_acc=0.1143\n",
            "Epoch 6: loss=2.5296, acc=0.1058, val_loss=45.7726, val_acc=0.1209\n",
            "Epoch 7: loss=2.5207, acc=0.1074, val_loss=85.2267, val_acc=0.1418\n",
            "Epoch 8: loss=2.5693, acc=0.1030, val_loss=117.2145, val_acc=0.1648\n",
            "Epoch 9: loss=2.5263, acc=0.1047, val_loss=194.1174, val_acc=0.1505\n",
            "Epoch 10: loss=2.4958, acc=0.1030, val_loss=640.0712, val_acc=0.1000\n",
            "Epoch 11: loss=2.4950, acc=0.1058, val_loss=715.5087, val_acc=0.1143\n",
            "Epoch 12: loss=2.5263, acc=0.1080, val_loss=720.9340, val_acc=0.1286\n",
            "Epoch 13: loss=2.5315, acc=0.0992, val_loss=1280.2083, val_acc=0.1286\n",
            "Epoch 14: loss=2.5359, acc=0.1113, val_loss=978.2520, val_acc=0.1451\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.0001_aug_True Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 4.7038\n",
            "Accuracy: 0.1723\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 3.7067\n",
            "Accuracy: 0.1542\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 4.7154\n",
            "Accuracy: 0.1622\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–†â–„â–†â–â–…â–†â–†â–…â–…â–…â–†â–‡â–ƒâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–„â–„â–‚â–ƒâ–‚â–‚â–„â–‚â–â–â–‚â–‚â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–‚â–ˆâ–‚â–ƒâ–…â–‡â–†â–â–‚â–„â–„â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–â–â–â–â–â–â–â–‚â–‚â–„â–…â–…â–ˆâ–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 0.11126\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 13\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 2.53591\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.14505\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 978.25195\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.15419\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 3.70674\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.17231\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 4.70377\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.16222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 4.71538\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.0001_aug_True\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/bflq4aos\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001432-bflq4aos/logs\u001b[0m\n",
            "\n",
            "Deney 35/36 tamamlandÄ±.\n",
            "\n",
            "==================== Deney 36/36 ====================\n",
            "Deney AdÄ±: exp_size_128_act_elu_lr_0.0001_aug_False\n",
            "Input Size: 128\n",
            "Activation: elu\n",
            "Learning Rate: 0.0001\n",
            "Data Augmentation: Pasif\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001837-n5qn9ch6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp_size_128_act_elu_lr_0.0001_aug_False\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/n5qn9ch6\u001b[0m\n",
            "\n",
            "Model Mimarisi:\n",
            "--------------------------------------------------\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer (\u001b[94mInputLayer\u001b[0m)             â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m3\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m896\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation (\u001b[94mActivation\u001b[0m)              â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization                  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m32\u001b[0m)        â”‚             \u001b[32m128\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d (\u001b[94mMaxPooling2D\u001b[0m)         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m32\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚          \u001b[32m18,496\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_1 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_1                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m)          â”‚             \u001b[32m256\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m64\u001b[0m)          â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚          \u001b[32m73,856\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_2 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_2                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m128\u001b[0m)         â”‚             \u001b[32m512\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2 (\u001b[94mMaxPooling2D\u001b[0m)       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m128\u001b[0m)         â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ flatten (\u001b[94mFlatten\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32768\u001b[0m)               â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense (\u001b[94mDense\u001b[0m)                        â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚       \u001b[32m8,388,864\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ activation_3 (\u001b[94mActivation\u001b[0m)            â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ batch_normalization_3                â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚           \u001b[32m1,024\u001b[0m â”‚\n",
            "â”‚ (\u001b[94mBatchNormalization\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)                    â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m256\u001b[0m)                 â”‚               \u001b[32m0\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dense_1 (\u001b[94mDense\u001b[0m)                      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m10\u001b[0m)                  â”‚           \u001b[32m2,570\u001b[0m â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,486,602\u001b[0m (32.37 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,485,642\u001b[0m (32.37 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m960\u001b[0m (3.75 KB)\n",
            "--------------------------------------------------\n",
            "\n",
            "EÄŸitim baÅŸlÄ±yor...\n",
            "Epoch 1/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.3782 - loss: 2.2420 - val_accuracy: 0.1055 - val_loss: 3.0641\n",
            "Epoch 2/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6686 - loss: 1.0390 - val_accuracy: 0.1044 - val_loss: 3.5766\n",
            "Epoch 3/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.6725 - val_accuracy: 0.1077 - val_loss: 3.9944\n",
            "Epoch 4/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9248 - loss: 0.3554 - val_accuracy: 0.1791 - val_loss: 2.9651\n",
            "Epoch 5/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9717 - loss: 0.2132 - val_accuracy: 0.1505 - val_loss: 3.2353\n",
            "Epoch 6/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9940 - loss: 0.1289 - val_accuracy: 0.3176 - val_loss: 2.2447\n",
            "Epoch 7/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9927 - loss: 0.1146 - val_accuracy: 0.3780 - val_loss: 2.2449\n",
            "Epoch 8/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0893 - val_accuracy: 0.4703 - val_loss: 1.7622\n",
            "Epoch 9/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0839 - val_accuracy: 0.5187 - val_loss: 1.6953\n",
            "Epoch 10/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0762 - val_accuracy: 0.5604 - val_loss: 1.5036\n",
            "Epoch 11/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0765 - val_accuracy: 0.5857 - val_loss: 1.5214\n",
            "Epoch 12/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0745 - val_accuracy: 0.5802 - val_loss: 1.5138\n",
            "Epoch 13/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0717 - val_accuracy: 0.5824 - val_loss: 1.5578\n",
            "Epoch 14/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.0792 - val_accuracy: 0.5923 - val_loss: 1.5494\n",
            "Epoch 15/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0724 - val_accuracy: 0.5989 - val_loss: 1.5250\n",
            "Epoch 16/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0712 - val_accuracy: 0.5868 - val_loss: 1.5663\n",
            "Epoch 17/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0691 - val_accuracy: 0.5923 - val_loss: 1.5566\n",
            "Epoch 18/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0683 - val_accuracy: 0.5978 - val_loss: 1.5316\n",
            "Epoch 19/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0680 - val_accuracy: 0.6011 - val_loss: 1.5417\n",
            "Epoch 20/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0684 - val_accuracy: 0.5879 - val_loss: 1.5448\n",
            "Epoch 21/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.5857 - val_loss: 1.5624\n",
            "Epoch 22/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.5912 - val_loss: 1.5445\n",
            "Epoch 23/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 0.5967 - val_loss: 1.5632\n",
            "Epoch 24/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0658 - val_accuracy: 0.5934 - val_loss: 1.5825\n",
            "Epoch 25/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0656 - val_accuracy: 0.6000 - val_loss: 1.5657\n",
            "Epoch 26/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0652 - val_accuracy: 0.5945 - val_loss: 1.5739\n",
            "Epoch 27/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0649 - val_accuracy: 0.5956 - val_loss: 1.5754\n",
            "Epoch 28/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0650 - val_accuracy: 0.6044 - val_loss: 1.5829\n",
            "Epoch 29/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0646 - val_accuracy: 0.6000 - val_loss: 1.5766\n",
            "Epoch 30/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0643 - val_accuracy: 0.6011 - val_loss: 1.6072\n",
            "Epoch 31/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0640 - val_accuracy: 0.5945 - val_loss: 1.5998\n",
            "Epoch 32/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.5956 - val_loss: 1.6084\n",
            "Epoch 33/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0636 - val_accuracy: 0.5978 - val_loss: 1.5737\n",
            "Epoch 34/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0633 - val_accuracy: 0.5967 - val_loss: 1.5727\n",
            "Epoch 35/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 0.6088 - val_loss: 1.5715\n",
            "Epoch 36/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0628 - val_accuracy: 0.5989 - val_loss: 1.6056\n",
            "Epoch 37/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0625 - val_accuracy: 0.5978 - val_loss: 1.5949\n",
            "Epoch 38/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 0.5912 - val_loss: 1.5909\n",
            "Epoch 39/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0621 - val_accuracy: 0.6022 - val_loss: 1.6041\n",
            "Epoch 40/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0617 - val_accuracy: 0.6000 - val_loss: 1.6375\n",
            "Epoch 41/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0614 - val_accuracy: 0.5967 - val_loss: 1.5924\n",
            "Epoch 42/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0611 - val_accuracy: 0.5923 - val_loss: 1.6206\n",
            "Epoch 43/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0609 - val_accuracy: 0.6011 - val_loss: 1.6216\n",
            "Epoch 44/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0606 - val_accuracy: 0.5857 - val_loss: 1.6355\n",
            "Epoch 45/100\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 0.5868 - val_loss: 1.6268\n",
            "\n",
            "EÄŸitim geÃ§miÅŸi:\n",
            "Epoch 1: loss=1.9007, acc=0.4415, val_loss=3.0641, val_acc=0.1055\n",
            "Epoch 2: loss=1.0340, acc=0.6742, val_loss=3.5766, val_acc=0.1044\n",
            "Epoch 3: loss=0.6596, acc=0.8099, val_loss=3.9944, val_acc=0.1077\n",
            "Epoch 4: loss=0.3611, acc=0.9206, val_loss=2.9651, val_acc=0.1791\n",
            "Epoch 5: loss=0.2024, acc=0.9736, val_loss=3.2353, val_acc=0.1505\n",
            "Epoch 6: loss=0.1344, acc=0.9923, val_loss=2.2447, val_acc=0.3176\n",
            "Epoch 7: loss=0.1090, acc=0.9953, val_loss=2.2449, val_acc=0.3780\n",
            "Epoch 8: loss=0.0908, acc=0.9989, val_loss=1.7622, val_acc=0.4703\n",
            "Epoch 9: loss=0.0829, acc=1.0000, val_loss=1.6953, val_acc=0.5187\n",
            "Epoch 10: loss=0.0770, acc=0.9997, val_loss=1.5036, val_acc=0.5604\n",
            "Epoch 11: loss=0.0759, acc=0.9997, val_loss=1.5214, val_acc=0.5857\n",
            "Epoch 12: loss=0.0734, acc=1.0000, val_loss=1.5138, val_acc=0.5802\n",
            "Epoch 13: loss=0.0734, acc=0.9997, val_loss=1.5578, val_acc=0.5824\n",
            "Epoch 14: loss=0.0767, acc=0.9995, val_loss=1.5494, val_acc=0.5923\n",
            "Epoch 15: loss=0.0718, acc=1.0000, val_loss=1.5250, val_acc=0.5989\n",
            "Epoch 16: loss=0.0706, acc=1.0000, val_loss=1.5663, val_acc=0.5868\n",
            "Epoch 17: loss=0.0690, acc=1.0000, val_loss=1.5566, val_acc=0.5923\n",
            "Epoch 18: loss=0.0683, acc=1.0000, val_loss=1.5316, val_acc=0.5978\n",
            "Epoch 19: loss=0.0680, acc=1.0000, val_loss=1.5417, val_acc=0.6011\n",
            "Epoch 20: loss=0.0675, acc=1.0000, val_loss=1.5448, val_acc=0.5879\n",
            "Epoch 21: loss=0.0671, acc=1.0000, val_loss=1.5624, val_acc=0.5857\n",
            "Epoch 22: loss=0.0666, acc=1.0000, val_loss=1.5445, val_acc=0.5912\n",
            "Epoch 23: loss=0.0662, acc=1.0000, val_loss=1.5632, val_acc=0.5967\n",
            "Epoch 24: loss=0.0659, acc=1.0000, val_loss=1.5825, val_acc=0.5934\n",
            "Epoch 25: loss=0.0656, acc=1.0000, val_loss=1.5657, val_acc=0.6000\n",
            "Epoch 26: loss=0.0653, acc=1.0000, val_loss=1.5739, val_acc=0.5945\n",
            "Epoch 27: loss=0.0650, acc=1.0000, val_loss=1.5754, val_acc=0.5956\n",
            "Epoch 28: loss=0.0649, acc=1.0000, val_loss=1.5829, val_acc=0.6044\n",
            "Epoch 29: loss=0.0646, acc=1.0000, val_loss=1.5766, val_acc=0.6000\n",
            "Epoch 30: loss=0.0643, acc=1.0000, val_loss=1.6072, val_acc=0.6011\n",
            "Epoch 31: loss=0.0640, acc=1.0000, val_loss=1.5998, val_acc=0.5945\n",
            "Epoch 32: loss=0.0637, acc=1.0000, val_loss=1.6084, val_acc=0.5956\n",
            "Epoch 33: loss=0.0636, acc=1.0000, val_loss=1.5737, val_acc=0.5978\n",
            "Epoch 34: loss=0.0633, acc=1.0000, val_loss=1.5727, val_acc=0.5967\n",
            "Epoch 35: loss=0.0630, acc=1.0000, val_loss=1.5715, val_acc=0.6088\n",
            "Epoch 36: loss=0.0628, acc=1.0000, val_loss=1.6056, val_acc=0.5989\n",
            "Epoch 37: loss=0.0625, acc=1.0000, val_loss=1.5949, val_acc=0.5978\n",
            "Epoch 38: loss=0.0623, acc=1.0000, val_loss=1.5909, val_acc=0.5912\n",
            "Epoch 39: loss=0.0621, acc=1.0000, val_loss=1.6041, val_acc=0.6022\n",
            "Epoch 40: loss=0.0617, acc=1.0000, val_loss=1.6375, val_acc=0.6000\n",
            "Epoch 41: loss=0.0614, acc=1.0000, val_loss=1.5924, val_acc=0.5967\n",
            "Epoch 42: loss=0.0611, acc=1.0000, val_loss=1.6206, val_acc=0.5923\n",
            "Epoch 43: loss=0.0608, acc=1.0000, val_loss=1.6216, val_acc=0.6011\n",
            "Epoch 44: loss=0.0605, acc=1.0000, val_loss=1.6355, val_acc=0.5857\n",
            "Epoch 45: loss=0.0602, acc=1.0000, val_loss=1.6268, val_acc=0.5868\n",
            "\n",
            "Test deÄŸerlendirmesi yapÄ±lÄ±yor...\n",
            "\n",
            "exp_size_128_act_elu_lr_0.0001_aug_False Test SonuÃ§larÄ±:\n",
            "--------------------------------------------------\n",
            "Orijinal Test:\n",
            "Loss: 1.6864\n",
            "Accuracy: 0.5744\n",
            "\n",
            "ManipÃ¼le EdilmiÅŸ Test:\n",
            "Loss: 4.4565\n",
            "Accuracy: 0.2737\n",
            "\n",
            "Renk SabitliÄŸi Test:\n",
            "Loss: 1.7349\n",
            "Accuracy: 0.5660\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy â–â–„â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy â–â–â–â–‚â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss â–…â–‡â–ˆâ–…â–†â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/accuracy 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch/epoch 44\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       epoch/learning_rate 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                epoch/loss 0.06023\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch/val_accuracy 0.58681\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            epoch/val_loss 1.62684\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_manipulated_accuracy 0.27368\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     test_manipulated_loss 4.45655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_original_accuracy 0.57436\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_original_loss 1.68636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test_wb_accuracy 0.56598\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test_wb_loss 1.73488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mexp_size_128_act_elu_lr_0.0001_aug_False\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification/runs/n5qn9ch6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/orhandijvar/bootcamp-cnn-animal-classification\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1mresults/wandb/wandb/run-20241223_001837-n5qn9ch6/logs\u001b[0m\n",
            "\n",
            "Deney 36/36 tamamlandÄ±.\n",
            "\n",
            "TÃ¼m deneyler tamamlandÄ±!\n",
            "\n",
            "==================== EN BAÅžARILI DENEY ====================\n",
            "Deney AdÄ±: exp_size_128_act_prelu_lr_0.001_aug_False\n",
            "\n",
            "KonfigÃ¼rasyon:\n",
            "Input Size: 128\n",
            "Aktivasyon: prelu\n",
            "Learning Rate: 0.001\n",
            "\n",
            "Test SonuÃ§larÄ±:\n",
            "Orijinal Test Accuracy: 0.6626\n",
            "ManipÃ¼le Test Accuracy: 0.2022\n",
            "Renk SabitliÄŸi Test Accuracy: 0.6545\n",
            "Ortalama Accuracy: 0.5064\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python src/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m97aVVwubQIR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Qv0si98cE_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
